
=== Checker



.Analysis Components in group Checker (2)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-JazzyChecker,JazzyChecker>>
|pass:[This annotator uses Jazzy for the decision whether a word is spelled correctly or not.]


|<<component-reference.adoc#engine-LanguageToolChecker,LanguageToolChecker>>
|pass:[Detect grammatical errors in text using LanguageTool a rule based grammar checker.]


|====



[[engine-JazzyChecker]]
==== JazzyChecker

[small]#*_Role_:* __Checker__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.jazzy-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.jazzy.JazzyChecker__#

++++
<div class='paragraph'><p>This annotator uses Jazzy for the decision whether a word is spelled correctly or not.</p></div>
++++


[discrete]
===== Parameters

`ScoreThreshold` (__Integer__) = `1` ::
+
++++
<div class='paragraph'><p>Determines the maximum edit distance (as an int value) that a suggestion for a spelling error may have.
E.g. if set to one suggestions are limited to words within edit distance 1 to the original word.</p></div>
++++

`modelEncoding` (__String__) = `UTF-8` ::
+
++++
<div class='paragraph'><p>The character encoding used by the model.</p></div>
++++

`modelLocation` (__String__)::
+
++++
<div class='paragraph'><p>Location from which the model is read. The model file is a simple word-list with one word
per line.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.anomaly.type.SpellingAnomaly,SpellingAnomaly>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.anomaly.type.SuggestedAction,SuggestedAction>>

|====





[[engine-LanguageToolChecker]]
==== LanguageToolChecker

[small]#*_Role_:* __Checker__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.languagetool-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.languagetool.LanguageToolChecker__#

++++
<div class='paragraph'><p>Detect grammatical errors in text using LanguageTool a rule based grammar checker.</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| __none specified__


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.anomaly.type.GrammarAnomaly,GrammarAnomaly>>

|====






=== Chunker



.Analysis Components in group Chunker (2)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-OpenNlpChunker,OpenNlpChunker>>
|pass:[Chunk annotator using OpenNLP.]


|<<component-reference.adoc#engine-TreeTaggerChunker,TreeTaggerChunker>>
|pass:[Chunk annotator using TreeTagger.]


|====



[[engine-OpenNlpChunker]]
==== OpenNlpChunker

[small]#*_Role_:* __Chunker__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.opennlp-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.opennlp.OpenNlpChunker__#

++++
<div class='paragraph'><p>Chunk annotator using OpenNLP.</p></div>
++++


[discrete]
===== Parameters

`ChunkMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the chunk tag to UIMA type mapping from this location instead of locating
the mapping automatically.</p></div>
++++

`internTags` (__Boolean__) = `true`  [optional]::
+
++++
<div class='paragraph'><p>Use the String#intern() method on tags. This is usually a good idea to avoid
spamming the heap with thousands of strings representing only a few different tags.

Default: true</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.

Default: false</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.chunk.Chunk,Chunk>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-chunker-en-default,default>>
|20100908.1


|====



[[engine-TreeTaggerChunker]]
==== TreeTaggerChunker

[small]#*_Role_:* __Chunker__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.treetagger-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.treetagger.TreeTaggerChunker__#

++++
<div class='paragraph'><p>Chunk annotator using TreeTagger.</p></div>
++++


[discrete]
===== Parameters

`ChunkMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location of the mapping file for chunk tags to UIMA types.</p></div>
++++

`executablePath` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this TreeTagger executable instead of trying to locate the executable automatically.</p></div>
++++

`flushSequence` (__String__) [optional]::
+
++++
<div class='paragraph'><p>A sequence to flush the internal TreeTagger buffer and to force it to output the rest of the
completed analysis. This is typically just a sequence of like 5-10 full stops (".") separated
by new line characters. However, some models may require a different flush sequence, e.g. a
short sentence in the respective language. For chunker models, mind that the sentence must
also be POS tagged, e.g. Nous-PRO:PER\n....</p></div>
++++

`internTags` (__Boolean__) = `true`  [optional]::
+
++++
<div class='paragraph'><p>Use the String#intern() method on tags. This is usually a good idea to avoid
spaming the heap with thousands of strings representing only a few different tags.

Default: true</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`performanceMode` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>TT4J setting: Disable some sanity checks, e.g. whether tokens contain line breaks (which is
not allowed). Turning this on will increase your performance, but the wrapper may throw
exceptions if illegal data is provided.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.

Default: false</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.chunk.Chunk,Chunk>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-chunker-de-le,le>>
|20110429.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-chunker-en-iso8859-le,iso8859-le>>
|20090824.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-chunker-en-le,le>>
|20140520.1


|fr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-chunker-fr-le,le>>
|20141218.2


|====




=== Coreference resolver



.Analysis Components in group Coreference resolver (1)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-StanfordCoreferenceResolver,StanfordCoreferenceResolver>>
|__No description__


|====



[[engine-StanfordCoreferenceResolver]]
==== StanfordCoreferenceResolver

[small]#*_Role_:* __Coreference resolver__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp.StanfordCoreferenceResolver__#

++++
null
++++


[discrete]
===== Parameters

`maxDist` (__Integer__) = `-1` ::
+
++++
<div class='paragraph'><p>DCoRef parameter: Maximum sentence distance between two mentions for resolution (-1: no
constraint on the distance)</p></div>
++++

`postprocessing` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>DCoRef parameter: Do post processing</p></div>
++++

`score` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>DCoRef parameter: Scoring the output of the system</p></div>
++++

`sieves` (__String__) = `MarkRole, DiscourseMatch, ExactStringMatch, RelaxedExactStringMatch, PreciseConstructs, StrictHeadMatch1, StrictHeadMatch2, StrictHeadMatch3, StrictHeadMatch4, RelaxedHeadMatch, PronounMatch` ::
+
++++
<div class='paragraph'><p>DCoRef parameter: Sieve passes - each class is defined in dcoref/sievepasses/.</p></div>
++++

`singleton` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>DCoRef parameter: setting singleton predictor</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity,NamedEntity>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent,Constituent>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.coref.type.CoreferenceChain,CoreferenceChain>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.coref.type.CoreferenceLink,CoreferenceLink>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-coref-en-default,default>>
|${core.version}.1


|====




=== Language Identifier



.Analysis Components in group Language Identifier (3)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-LangDetectLanguageIdentifier,LangDetectLanguageIdentifier>>
|pass:[Langdetect language identifier based on character n-grams.]


|<<component-reference.adoc#engine-LanguageDetectorWeb1T,LanguageDetectorWeb1T>>
|pass:[Language detector based on n-gram frequency counts, e.g. as provided by Web1T]


|<<component-reference.adoc#engine-LanguageIdentifier,LanguageIdentifier>>
|pass:[Detection based on character n-grams.]


|====



[[engine-LangDetectLanguageIdentifier]]
==== LangDetectLanguageIdentifier

[small]#*_Role_:* __Language Identifier__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.langdetect-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.langdetect.LangDetectLanguageIdentifier__#

++++
<div class='paragraph'><p>Langdetect language identifier based on character n-grams.</p></div>
++++


[discrete]
===== Parameters

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location from which the model is read.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Variant of a model the model. Used to address a specific model if here are multiple models
for one language.</p></div>
++++






[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|any
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.langdetect-model-languageidentifier-any-socialmedia,socialmedia>>
|20141013.1


|any
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.langdetect-model-languageidentifier-any-wikipedia,wikipedia>>
|20141013.1


|====



[[engine-LanguageDetectorWeb1T]]
==== LanguageDetectorWeb1T

[small]#*_Role_:* __Language Identifier__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.ldweb1t-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.ldweb1t.LanguageDetectorWeb1T__#

++++
<div class='paragraph'><p>Language detector based on n-gram frequency counts, e.g. as provided by Web1T</p></div>
++++


[discrete]
===== Parameters

`maxNGramSize` (__Integer__) = `3` ::
+
++++
<div class='paragraph'><p>The maximum n-gram size that should be considered. Default is 3.</p></div>
++++

`minNGramSize` (__Integer__) = `1` ::
+
++++
<div class='paragraph'><p>The minimum n-gram size that should be considered. Default is 1.</p></div>
++++








[[engine-LanguageIdentifier]]
==== LanguageIdentifier

[small]#*_Role_:* __Language Identifier__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textcat-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textcat.LanguageIdentifier__#

++++
<div class='paragraph'><p>Detection based on character n-grams. Uses the <a href="http://textcat.sourceforge.net">Java
Text Categorizing Library</a> based on a technique by Cavnar and Trenkle.</p>

<p>References:</p>
<ul>
<li>Cavnar, W. B. and J. M. Trenkle (1994). N-Gram-Based Text Categorization. 
In Proceedings of Third Annual Symposium on Document Analysis and Information Retrieval, 
Las Vegas, NV, UNLV Publications/Reprographics, pp. 161-175, 11-13 April 1994.</li></ul></div>
++++









=== Lemmatizer



.Analysis Components in group Lemmatizer (6)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-ClearNlpLemmatizer,ClearNlpLemmatizer>>
|pass:[Lemmatizer using Clear NLP.]


|<<component-reference.adoc#engine-GateLemmatizer,GateLemmatizer>>
|pass:[Wrapper for the GATE rule based lemmatizer.]


|<<component-reference.adoc#engine-LanguageToolLemmatizer,LanguageToolLemmatizer>>
|pass:[Naive lexicon-based lemmatizer.]


|<<component-reference.adoc#engine-MateLemmatizer,MateLemmatizer>>
|pass:[DKPro Annotator for the MateToolsLemmatizer.]


|<<component-reference.adoc#engine-MorphaLemmatizer,MorphaLemmatizer>>
|pass:[Lemmatize based on a finite-state machine.]


|<<component-reference.adoc#engine-StanfordLemmatizer,StanfordLemmatizer>>
|pass:[Stanford Lemmatizer component.]


|====



[[engine-ClearNlpLemmatizer]]
==== ClearNlpLemmatizer

[small]#*_Role_:* __Lemmatizer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.clearnlp-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.clearnlp.ClearNlpLemmatizer__#

++++
<div class='paragraph'><p>Lemmatizer using Clear NLP.</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) = `en`  [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.clearnlp-model-dictionary-en-default,default>>
|20130715.0


|====



[[engine-GateLemmatizer]]
==== GateLemmatizer

[small]#*_Role_:* __Lemmatizer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.gate-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.gate.GateLemmatizer__#

++++
<div class='paragraph'><p>Wrapper for the GATE rule based lemmatizer.

Based on code by Asher Stern from the BIUTEE textual entailment tool.</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++








[[engine-LanguageToolLemmatizer]]
==== LanguageToolLemmatizer

[small]#*_Role_:* __Lemmatizer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.languagetool-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.languagetool.LanguageToolLemmatizer__#

++++
<div class='paragraph'><p>Naive lexicon-based lemmatizer. The words are looked up using the wordform lexicons of
LanguageTool. Multiple readings are produced. The annotator simply takes the most frequent
lemma from those readings. If no readings could be found, the original text is assigned as
lemma.</p></div>
++++


[discrete]
===== Parameters

`sanitize` (__Boolean__) = `true` ::
+
++++

++++

`sanitizeChars` (__String[]__) = `[(, ), [, ]]` ::
+
++++

++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>

|====





[[engine-MateLemmatizer]]
==== MateLemmatizer

[small]#*_Role_:* __Lemmatizer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.matetools-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.matetools.MateLemmatizer__#

++++
<div class='paragraph'><p>DKPro Annotator for the MateToolsLemmatizer.</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`uppercase` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Try reconstructing proper casing for lemmata. This is useful for German, but e.g. for 
English creates odd results.</p></div>
++++

`variant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-lemmatizer-de-tiger,tiger>>
|20121024.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-lemmatizer-en-conll2009,conll2009>>
|20130117.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-lemmatizer-es-conll2009,conll2009>>
|20130117.1


|fr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-lemmatizer-fr-ftb,ftb>>
|20130918.0


|====



[[engine-MorphaLemmatizer]]
==== MorphaLemmatizer

[small]#*_Role_:* __Lemmatizer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.morpha-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.morpha.MorphaLemmatizer__#

++++
<div class='paragraph'><p>Lemmatize based on a finite-state machine. Uses the <a href="https://github.com/knowitall/morpha">
Java port</a> of <a href="http://www.informatics.sussex.ac.uk/research/groups/nlp/carroll/morph.html">Morpha</a>.

</p><p>References:</p>
<ul>
<li>Minnen, G., J. Carroll and D. Pearce (2001). Applied morphological 
processing of English, Natural Language Engineering, 7(3). 207-223.</li>
</ul></div>
++++


[discrete]
===== Parameters

`readPOS` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Pass part-of-speech information on to Morpha. Since we currently do not know in which format
the part-of-speech tags are expected by Morpha, we just pass on the actual pos tag value
we get from the token. This may produce worse results than not passing on pos tags at all,
so this is disabled by default.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>

|====





[[engine-StanfordLemmatizer]]
==== StanfordLemmatizer

[small]#*_Role_:* __Lemmatizer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp.StanfordLemmatizer__#

++++
<div class='paragraph'><p>Stanford Lemmatizer component. The Stanford Morphology-class computes the base form of English
words, by removing just inflections (not derivational morphology). That is, it only does noun
plurals, pronoun case, and verb endings, and not things like comparative adjectives or derived
nominals. It is based on a finite-state transducer implemented by John Carroll et al., written in
flex and publicly available. See:
http://www.informatics.susx.ac.uk/research/nlp/carroll/morph.html

</p><p>This only works for ENGLISH.</p></div>
++++


[discrete]
===== Parameters

`ptb3Escaping` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Enable all traditional PTB3 token transforms (like -LRB-, -RRB-).</p></div>
++++

`quoteBegin` (__String[]__) [optional]::
+
++++
<div class='paragraph'><p>List of extra token texts (usually single character strings) that should be treated like
opening quotes and escaped accordingly before being sent to the parser.</p></div>
++++

`quoteEnd` (__String[]__) [optional]::
+
++++
<div class='paragraph'><p>List of extra token texts (usually single character strings) that should be treated like
closing quotes and escaped accordingly before being sent to the parser.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>

|====






=== Morphological analyzer



.Analysis Components in group Morphological analyzer (2)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-RfTagger,RfTagger>>
|pass:[Rftagger morphological analyzer.]


|<<component-reference.adoc#engine-SfstAnnotator,SfstAnnotator>>
|pass:[Sfst morphological analyzer.]


|====



[[engine-RfTagger]]
==== RfTagger

[small]#*_Role_:* __Morphological analyzer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.rftagger-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.rftagger.RfTagger__#

++++
<div class='paragraph'><p>Rftagger morphological analyzer.</p></div>
++++


[discrete]
===== Parameters

`MorphMappingLocation` (__String__) [optional]::
+
++++

++++

`POSMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the part-of-speech tag to UIMA type mapping from this location instead of locating the
mapping automatically.</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelEncoding` (__String__) [optional]::
+
++++
<div class='paragraph'><p>The character encoding used by the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Write the tag set(s) to the log when a model is loaded.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.morph.MorphologicalFeatures,MorphologicalFeatures>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|cz
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.rftagger-model-morph-cz-cac,cac>>
|20150728.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.rftagger-model-morph-de-tiger,tiger>>
|20150928.1


|hu
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.rftagger-model-morph-hu-szeged,szeged>>
|20150728.1


|ru
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.rftagger-model-morph-ru-ric,ric>>
|20150728.1


|sk
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.rftagger-model-morph-sk-snk,snk>>
|20150728.1


|sl
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.rftagger-model-morph-sl-jos,jos>>
|20150728.1


|====



[[engine-SfstAnnotator]]
==== SfstAnnotator

[small]#*_Role_:* __Morphological analyzer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.sfst-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.sfst.SfstAnnotator__#

++++
<div class='paragraph'><p>Sfst morphological analyzer.</p></div>
++++


[discrete]
===== Parameters

`MorphMappingLocation` (__String__) [optional]::
+
++++

++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`mode` (__String__) = `FIRST` ::
+
++++

++++

`modelEncoding` (__String__) = `UTF-8` ::
+
++++
<div class='paragraph'><p>Specifies the model encoding.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Write the tag set(s) to the log when a model is loaded.</p></div>
++++

`writeLemma` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Write lemma information.

Default: true</p></div>
++++

`writePOS` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Write part-of-speech information.

Default: true</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.morph.MorphologicalFeatures,MorphologicalFeatures>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.sfst-model-morph-de-morphisto-ca,morphisto-ca>>
|20110202.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.sfst-model-morph-de-smor-ca,smor-ca>>
|20140801.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.sfst-model-morph-de-zmorge-newlemma-ca,zmorge-newlemma-ca>>
|20140521.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.sfst-model-morph-de-zmorge-orig-ca,zmorge-orig-ca>>
|20140521.1


|it
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.sfst-model-morph-it-pippi-ca,pippi-ca>>
|20090223.1


|tr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.sfst-model-morph-tr-trmorph-ca,trmorph-ca>>
|20130219.1


|====




=== Named Entity Recognizer



.Analysis Components in group Named Entity Recognizer (2)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-OpenNlpNamedEntityRecognizer,OpenNlpNamedEntityRecognizer>>
|pass:[OpenNLP name finder wrapper.]


|<<component-reference.adoc#engine-StanfordNamedEntityRecognizer,StanfordNamedEntityRecognizer>>
|pass:[Stanford Named Entity Recognizer component.]


|====



[[engine-OpenNlpNamedEntityRecognizer]]
==== OpenNlpNamedEntityRecognizer

[small]#*_Role_:* __Named Entity Recognizer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.opennlp-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.opennlp.OpenNlpNamedEntityRecognizer__#

++++
<div class='paragraph'><p>OpenNLP name finder wrapper.</p></div>
++++


[discrete]
===== Parameters

`NamedEntityMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location of the mapping file for named entity tags to UIMA types.</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location from which the model is read.</p></div>
++++

`modelVariant` (__String__) = `person` ::
+
++++
<div class='paragraph'><p>Variant of a model the model. Used to address a specific model if here are multiple models
for one language.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity,NamedEntity>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-en-date,date>>
|20100907.0


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-en-location,location>>
|20100907.0


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-en-money,money>>
|20100907.0


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-en-organization,organization>>
|20100907.0


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-en-percentage,percentage>>
|20100907.0


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-en-person,person>>
|20130624.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-en-time,time>>
|20100907.0


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-es-location,location>>
|20100908.0


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-es-misc,misc>>
|20100908.0


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-es-organization,organization>>
|20100908.0


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-es-person,person>>
|20100908.0


|nl
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-nl-location,location>>
|20100908.0


|nl
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-nl-misc,misc>>
|20100908.0


|nl
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-nl-organization,organization>>
|20100908.0


|nl
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-ner-nl-person,person>>
|20100908.0


|====



[[engine-StanfordNamedEntityRecognizer]]
==== StanfordNamedEntityRecognizer

[small]#*_Role_:* __Named Entity Recognizer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp.StanfordNamedEntityRecognizer__#

++++
<div class='paragraph'><p>Stanford Named Entity Recognizer component.</p></div>
++++


[discrete]
===== Parameters

`NamedEntityMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location of the mapping file for named entity tags to UIMA types.</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location from which the model is read.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Variant of a model the model. Used to address a specific model if here are multiple models
for one language.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.</p></div>
++++

`ptb3Escaping` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Enable all traditional PTB3 token transforms (like -LRB-, -RRB-).</p></div>
++++

`quoteBegin` (__String[]__) [optional]::
+
++++
<div class='paragraph'><p>List of extra token texts (usually single character strings) that should be treated like
opening quotes and escaped accordingly before being sent to the parser.</p></div>
++++

`quoteEnd` (__String[]__) [optional]::
+
++++
<div class='paragraph'><p>List of extra token texts (usually single character strings) that should be treated like
closing quotes and escaped accordingly before being sent to the parser.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity,NamedEntity>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-ner-de-dewac_175m_600.crf,dewac_175m_600.crf>>
|20150130.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-ner-de-hgc_175m_600.crf,hgc_175m_600.crf>>
|20150130.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-ner-en-all.3class.caseless.distsim.crf,all.3class.caseless.distsim.crf>>
|20160110.0


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-ner-en-all.3class.distsim.crf,all.3class.distsim.crf>>
|20150420.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-ner-en-all.3class.nodistsim.crf,all.3class.nodistsim.crf>>
|20160110.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-ner-en-conll.4class.caseless.distsim.crf,conll.4class.caseless.distsim.crf>>
|20160110.0


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-ner-en-conll.4class.distsim.crf,conll.4class.distsim.crf>>
|20150420.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-ner-en-conll.4class.nodistsim.crf,conll.4class.nodistsim.crf>>
|20160110.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-ner-en-muc.7class.caseless.distsim.crf,muc.7class.caseless.distsim.crf>>
|20150129.0


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-ner-en-muc.7class.distsim.crf,muc.7class.distsim.crf>>
|20150129.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-ner-en-muc.7class.nodistsim.crf,muc.7class.nodistsim.crf>>
|20160110.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-ner-en-nowiki.3class.caseless.distsim.crf,nowiki.3class.caseless.distsim.crf>>
|20160110.0


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-ner-en-nowiki.3class.nodistsim.crf,nowiki.3class.nodistsim.crf>>
|20160110.0


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-ner-es-ancora.distsim.s512.crf,ancora.distsim.s512.crf>>
|20140826.1


|====




=== Parser



.Analysis Components in group Parser (7)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-BerkeleyParser,BerkeleyParser>>
|pass:[Berkeley Parser annotator .]


|<<component-reference.adoc#engine-ClearNlpParser,ClearNlpParser>>
|pass:[Clear parser annotator.]


|<<component-reference.adoc#engine-MaltParser,MaltParser>>
|pass:[Dependency parsing using MaltPaser.]


|<<component-reference.adoc#engine-MateParser,MateParser>>
|pass:[DKPro Annotator for the MateToolsParser.]


|<<component-reference.adoc#engine-MstParser,MstParser>>
|pass:[Dependency parsing using MSTParser.]


|<<component-reference.adoc#engine-OpenNlpParser,OpenNlpParser>>
|pass:[OpenNLP parser.]


|<<component-reference.adoc#engine-StanfordParser,StanfordParser>>
|pass:[Stanford Parser component.]


|====



[[engine-BerkeleyParser]]
==== BerkeleyParser

[small]#*_Role_:* __Parser__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.berkeleyparser-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.berkeleyparser.BerkeleyParser__#

++++
<div class='paragraph'><p>Berkeley Parser annotator . Requires Sentences to be annotated before.</p></div>
++++


[discrete]
===== Parameters

`ConstituentMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location of the mapping file for constituent tags to UIMA types.</p></div>
++++

`POSMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location of the mapping file for part-of-speech tags to UIMA types.</p></div>
++++

`accurate` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Set thresholds for accuracy.
</p><p>
Default: false (set thresholds for efficiency)</div>
++++

`binarize` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Output binarized trees.
</p><p>
Default: false</div>
++++

`internTags` (__Boolean__) = `true`  [optional]::
+
++++
<div class='paragraph'><p>Use the String#intern() method on tags. This is usually a good idea to avoid spaming
the heap with thousands of strings representing only a few different tags.

Default: true</p></div>
++++

`keepFunctionLabels` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Retain predicted function labels. Model must have been trained with function labels.
</p><p>
Default: false</div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the language set in the CAS to locate the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.

Default: false</p></div>
++++

`readPOS` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Sets whether to use or not to use already existing POS tags from another annotator for the
parsing process.
</p><p>
Default: false</div>
++++

`scores` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Output inside scores (only for binarized viterbi trees).
</p><p>
Default: false</div>
++++

`substates` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Output sub-categories (only for binarized Viterbi trees).
</p><p>
Default: false</div>
++++

`variational` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Use variational rule score approximation instead of max-rule
</p><p>
Default: false</div>
++++

`viterbi` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Compute Viterbi derivation instead of max-rule tree.
</p><p>
Default: false (max-rule)</div>
++++

`writePOS` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Sets whether to create or not to create POS tags. The creation of constituent tags must be
turned on for this to work.
</p><p>
Default: true</div>
++++

`writePennTree` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>If this parameter is set to true, each sentence is annotated with a PennTree-Annotation,
containing the whole parse tree in Penn Treebank style format.
</p><p>
Default: false</div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.PennTree,PennTree>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent,Constituent>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|ar
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.berkeleyparser-model-parser-ar-sm5,sm5>>
|20090917.1


|bg
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.berkeleyparser-model-parser-bg-sm5,sm5>>
|20090917.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.berkeleyparser-model-parser-de-sm5,sm5>>
|20090917.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.berkeleyparser-model-parser-en-sm6,sm6>>
|20100819.1


|fr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.berkeleyparser-model-parser-fr-sm5,sm5>>
|20090917.1


|zh
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.berkeleyparser-model-parser-zh-sm5,sm5>>
|20090917.1


|====



[[engine-ClearNlpParser]]
==== ClearNlpParser

[small]#*_Role_:* __Parser__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.clearnlp-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.clearnlp.ClearNlpParser__#

++++
<div class='paragraph'><p>Clear parser annotator.</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location from which the model is read.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Variant of a model the model. Used to address a specific model if here are multiple models
for one language.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Write the tag set(s) to the log when a model is loaded.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency,Dependency>>

|====





[[engine-MaltParser]]
==== MaltParser

[small]#*_Role_:* __Parser__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.maltparser-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.maltparser.MaltParser__#

++++
<div class='paragraph'><p>Dependency parsing using MaltPaser.
</p><p>
Required annotations:
</p>
<ul>
<li>Token</li>
<li>Sentence</li>
<li>POS</li>
</ul>

Generated annotations:
<ul>
<li>Dependency (annotated over sentence-span)</li>
</ul></div>
++++


[discrete]
===== Parameters

`ignoreMissingFeatures` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Process anyway, even if the model relies on features that are not supported by this
component.

Default: false</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.

Default: false</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency,Dependency>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|bn
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.maltparser-model-parser-bn-linear,linear>>
|20120905.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.maltparser-model-parser-en-linear,linear>>
|20120312.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.maltparser-model-parser-en-poly,poly>>
|20120312.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.maltparser-model-parser-es-linear,linear>>
|20130220.0


|fa
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.maltparser-model-parser-fa-linear,linear>>
|20130522.1


|fr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.maltparser-model-parser-fr-linear,linear>>
|20120312.1


|pl
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.maltparser-model-parser-pl-linear,linear>>
|20120904.1


|sv
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.maltparser-model-parser-sv-linear,linear>>
|20120925.2


|====



[[engine-MateParser]]
==== MateParser

[small]#*_Role_:* __Parser__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.matetools-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.matetools.MateParser__#

++++
<div class='paragraph'><p>DKPro Annotator for the MateToolsParser.

</p><p>
Please cite the following paper, if you use the parser: Bernd Bohnet. 2010. Top Accuracy and Fast
Dependency Parsing is not a Contradiction. The 23rd International Conference on Computational
Linguistics (COLING 2010), Beijing, China.
</p></div>
++++


[discrete]
===== Parameters

`DependencyMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the dependency to UIMA type mapping from this location instead of locating
the mapping automatically.</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.

Default: false</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency,Dependency>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-parser-de-tiger,tiger>>
|20121024.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-parser-en-conll2009,conll2009>>
|20130117.2


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-parser-es-conll2009,conll2009>>
|20130117.1


|fr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-parser-fr-ftb,ftb>>
|20130918.0


|zh
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-parser-zh-conll2009,conll2009>>
|20130117.1


|====



[[engine-MstParser]]
==== MstParser

[small]#*_Role_:* __Parser__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.mstparser-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.mstparser.MstParser__#

++++
<div class='paragraph'><p>Dependency parsing using MSTParser.
</p><p>
Wrapper for the MSTParser (<b>high memory requirements</b>). More information about the parser
can be found <a href="http://www.seas.upenn.edu/~strctlrn/MSTParser/MSTParser.html">here</a> <a
href="http://sourceforge.net/projects/mstparser/">here</a>
</p>
<p>
The MSTParser models tend to be very large, e.g. the <a
href="http://nlp.stanford.edu/software/stanford-dependencies.shtml">Eisner</a> model is about 600
MB uncompressed. With this model, parsing a simple sentence with MSTParser requires about 3 GB
heap memory.
</p>
<p>
This component feeds MSTParser only with the FORM (token) and POS (part-of-speech) fields. LEMMA,
CPOS, and other columns from the CONLL 2006 format are not generated (cf.
mstparser.DependencyInstance DependencyInstance).
</p></div>
++++


[discrete]
===== Parameters

`DependencyMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the dependency to UIMA type mapping from this location instead of locating
the mapping automatically.</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`order` (__Integer__) [optional]::
+
++++
<div class='paragraph'><p>Specifies the order/scope of features. 1 only has features over single edges
and 2 has features over pairs of adjacent edges in the tree. The model must have been
trained with the respective order set here.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.

Default: false</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency,Dependency>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.mstparser-model-parser-en-eisner,eisner>>
|20100416.2


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.mstparser-model-parser-en-sample,sample>>
|20121019.2


|hr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.mstparser-model-parser-hr-mte5.defnpout,mte5.defnpout>>
|20130527.1


|hr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.mstparser-model-parser-hr-mte5.pos,mte5.pos>>
|20130527.1


|====



[[engine-OpenNlpParser]]
==== OpenNlpParser

[small]#*_Role_:* __Parser__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.opennlp-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.opennlp.OpenNlpParser__#

++++
<div class='paragraph'><p>OpenNLP parser. The parser ignores existing POS tags and internally creates new ones. However,
these tags are only added as annotation if explicitly requested via #PARAM_WRITE_POS.</p></div>
++++


[discrete]
===== Parameters

`ConstituentMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location of the mapping file for constituent tags to UIMA types.</p></div>
++++

`POSMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the part-of-speech tag to UIMA type mapping from this location instead of locating
the mapping automatically.</p></div>
++++

`internTags` (__Boolean__) = `true`  [optional]::
+
++++
<div class='paragraph'><p>Use the String#intern() method on tags. This is usually a good idea to avoid
spaming the heap with thousands of strings representing only a few different tags.

</p><p>Default: true</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.

</p><p>Default: false</p></div>
++++

`writePOS` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Sets whether to create or not to create POS tags. The creation of
constituent tags must be turned on for this to work.

</p><p>Default: true</p></div>
++++

`writePennTree` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>If this parameter is set to true, each sentence is annotated with a PennTree-Annotation,
containing the whole parse tree in Penn Treebank style format.

</p><p>Default: false</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.PennTree,PennTree>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent,Constituent>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-parser-en-chunking,chunking>>
|20120616.1


|====



[[engine-StanfordParser]]
==== StanfordParser

[small]#*_Role_:* __Parser__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp.StanfordParser__#

++++
<div class='paragraph'><p>Stanford Parser component.</p></div>
++++


[discrete]
===== Parameters

`ConstituentMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location of the mapping file for constituent tags to UIMA types.</p></div>
++++

`POSMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location of the mapping file for part-of-speech tags to UIMA types.</p></div>
++++

`annotationTypeToParse` (__String__) [optional]::
+
++++
<div class='paragraph'><p>This parameter can be used to override the standard behavior which uses the <i>Sentence</i>
annotation as the basic unit for parsing.
</p><p>If the parameter is set with the name of an annotation type <i>x</i>, the parser will no
longer parse <i>Sentence</i>-annotations, but <i>x</i>-Annotations.</p>
<p>Default: null</div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model and tag set mapping.</p></div>
++++

`maxItems` (__Integer__) = `200000` ::
+
++++
<div class='paragraph'><p>Controls when the factored parser considers a sentence to be too complex and falls back to
the PCFG parser.
</p><p>
Default: 200000</div>
++++

`maxSentenceLength` (__Integer__) = `130` ::
+
++++
<div class='paragraph'><p>Maximum number of tokens in a sentence. Longer sentences are not parsed. This is to avoid out
of memory exceptions.
</p><p>
Default: 130</div>
++++

`mode` (__String__) = `TREE`  [optional]::
+
++++
<div class='paragraph'><p>Sets the kind of dependencies being created.

</p><p>Default: DependenciesMode#COLLAPSED TREE</div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location from which the model is read.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Variant of a model the model. Used to address a specific model if here are multiple models
for one language.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Write the tag set(s) to the log when a model is loaded.</p></div>
++++

`ptb3Escaping` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Enable all traditional PTB3 token transforms (like -LRB-, -RRB-).</p></div>
++++

`quoteBegin` (__String[]__) [optional]::
+
++++
<div class='paragraph'><p>List of extra token texts (usually single character strings) that should be treated like
opening quotes and escaped accordingly before being sent to the parser.</p></div>
++++

`quoteEnd` (__String[]__) [optional]::
+
++++
<div class='paragraph'><p>List of extra token texts (usually single character strings) that should be treated like
closing quotes and escaped accordingly before being sent to the parser.</p></div>
++++

`readPOS` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Sets whether to use or not to use already existing POS tags from another annotator for the
parsing process.
</p><p>
Default: true</div>
++++

`writeConstituent` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Sets whether to create or not to create constituent tags. This is required for POS-tagging
and lemmatization.
</p><p>
Default: true</div>
++++

`writeDependency` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Sets whether to create or not to create dependency annotations.

</p><p>Default: true</div>
++++

`writePOS` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Sets whether to create or not to create POS tags. The creation of constituent tags must be
turned on for this to work.
</p><p>
Default: false</div>
++++

`writePennTree` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>If this parameter is set to true, each sentence is annotated with a PennTree-Annotation,
containing the whole parse tree in Penn Treebank style format.
</p><p>
Default: false</div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent,Constituent>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|ar
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-ar-factored,factored>>
|20150129.1


|ar
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-ar-sr,sr>>
|20141031.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-de-factored,factored>>
|20150129.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-de-pcfg,pcfg>>
|20150129.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-de-sr,sr>>
|20141031.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-en-factored,factored>>
|20150129.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-en-pcfg,pcfg>>
|20150129.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-en-pcfg.caseless,pcfg.caseless>>
|20160110.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-en-rnn,rnn>>
|20140104.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-en-sr,sr>>
|20141031.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-en-sr-beam,sr-beam>>
|20141031.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-en-wsj-factored,wsj-factored>>
|20150129.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-en-wsj-pcfg,wsj-pcfg>>
|20150129.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-en-wsj-rnn,wsj-rnn>>
|20140104.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-es-pcfg,pcfg>>
|20150108.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-es-sr,sr>>
|20141023.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-es-sr-beam,sr-beam>>
|20141023.1


|fr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-fr-factored,factored>>
|20150129.1


|fr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-fr-sr,sr>>
|20160114.1


|fr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-fr-sr-beam,sr-beam>>
|20141023.1


|zh
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-zh-factored,factored>>
|20150129.1


|zh
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-zh-pcfg,pcfg>>
|20150129.1


|zh
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-zh-sr,sr>>
|20141023.1


|zh
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-zh-xinhua-factored,xinhua-factored>>
|20150129.1


|zh
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-parser-zh-xinhua-pcfg,xinhua-pcfg>>
|20150129.1


|====




=== Part-of-speech tagger



.Analysis Components in group Part-of-speech tagger (10)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-ArktweetPosTagger,ArktweetPosTagger>>
|pass:[Wrapper for Twitter Tokenizer and POS Tagger.]


|<<component-reference.adoc#engine-ClearNlpPosTagger,ClearNlpPosTagger>>
|pass:[Part-of-Speech annotator using Clear NLP.]


|<<component-reference.adoc#engine-HepplePosTagger,HepplePosTagger>>
|pass:[GATE Hepple part-of-speech tagger.]


|<<component-reference.adoc#engine-HunPosTagger,HunPosTagger>>
|pass:[Part-of-Speech annotator using HunPos.]


|<<component-reference.adoc#engine-MateMorphTagger,MateMorphTagger>>
|pass:[DKPro Annotator for the MateToolsMorphTagger.]


|<<component-reference.adoc#engine-MatePosTagger,MatePosTagger>>
|pass:[DKPro Annotator for the MateToolsPosTagger]


|<<component-reference.adoc#engine-MeCabTagger,MeCabTagger>>
|pass:[Annotator for the MeCab Japanese POS Tagger.]


|<<component-reference.adoc#engine-OpenNlpPosTagger,OpenNlpPosTagger>>
|pass:[Part-of-Speech annotator using OpenNLP.]


|<<component-reference.adoc#engine-StanfordPosTagger,StanfordPosTagger>>
|pass:[Stanford Part-of-Speech tagger component.]


|<<component-reference.adoc#engine-TreeTaggerPosTagger,TreeTaggerPosTagger>>
|pass:[Part-of-Speech and lemmatizer annotator using TreeTagger.]


|====



[[engine-ArktweetPosTagger]]
==== ArktweetPosTagger

[small]#*_Role_:* __Part-of-speech tagger__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.arktools-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.arktools.ArktweetPosTagger__#

++++
<div class='paragraph'><p>Wrapper for Twitter Tokenizer and POS Tagger.

As described in: Olutobi Owoputi, Brendan O’Connor, Chris Dyer, Kevin Gimpel, Nathan Schneider
and Noah A. Smith. Improved Part-of-Speech Tagging for Online Conversational Text with Word
Clusters In Proceedings of NAACL 2013.</p></div>
++++


[discrete]
===== Parameters

`POSMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location of the mapping file for part-of-speech tags to UIMA types.</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model and tag set mapping.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location from which the model is read.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Variant of a model the model. Used to address a specific model if here are multiple models
for one language.</p></div>
++++






[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.arktools-model-tagger-en-default,default>>
|20120919.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.arktools-model-tagger-en-irc,irc>>
|20121211.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.arktools-model-tagger-en-ritter,ritter>>
|20130723.1


|====



[[engine-ClearNlpPosTagger]]
==== ClearNlpPosTagger

[small]#*_Role_:* __Part-of-speech tagger__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.clearnlp-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.clearnlp.ClearNlpPosTagger__#

++++
<div class='paragraph'><p>Part-of-Speech annotator using Clear NLP. Requires Sentences to be annotated before.</p></div>
++++


[discrete]
===== Parameters

`POSMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the part-of-speech tag to UIMA type mapping from this location instead of locating the
mapping automatically.</p></div>
++++

`dictLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the dictionary from this location instead of locating the dictionary automatically.</p></div>
++++

`dictVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the dictionary.</p></div>
++++

`internTags` (__Boolean__) = `true`  [optional]::
+
++++
<div class='paragraph'><p>Use the String#intern() method on tags. This is usually a good idea to avoid spaming
the heap with thousands of strings representing only a few different tags.</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the pos-tagging model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the pos-tagging model.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>

|====





[[engine-HepplePosTagger]]
==== HepplePosTagger

[small]#*_Role_:* __Part-of-speech tagger__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.gate-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.gate.HepplePosTagger__#

++++
<div class='paragraph'><p>GATE Hepple part-of-speech tagger.</p></div>
++++


[discrete]
===== Parameters

`POSMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the part-of-speech tag to UIMA type mapping from this location instead of locating
the mapping automatically.</p></div>
++++

`internTags` (__Boolean__) = `true`  [optional]::
+
++++
<div class='paragraph'><p>Use the String#intern() method on tags. This is usually a good idea to avoid
spaming the heap with thousands of strings representing only a few different tags.

Default: true</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`lexiconLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the lexicon from this location instead of locating it automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.

Default: false</p></div>
++++

`rulesetLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the ruleset from this location instead of locating it automatically.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>

|====





[[engine-HunPosTagger]]
==== HunPosTagger

[small]#*_Role_:* __Part-of-speech tagger__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.hunpos-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.hunpos.HunPosTagger__#

++++
<div class='paragraph'><p>Part-of-Speech annotator using HunPos. Requires Sentences to be annotated before.</p></div>
++++


[discrete]
===== Parameters

`POSMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the part-of-speech tag to UIMA type mapping from this location instead of locating the
mapping automatically.</p></div>
++++

`internTags` (__Boolean__) = `true`  [optional]::
+
++++
<div class='paragraph'><p>Use the String#intern() method on tags. This is usually a good idea to avoid spaming
the heap with thousands of strings representing only a few different tags.

Default: true</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.

Default: false</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|cs
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-cs-pdt,pdt>>
|20121123.2


|da
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-da-ddt,ddt>>
|20121123.2


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-de-tiger,tiger>>
|20121123.2


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-en-wsj,wsj>>
|20070724.2


|fa
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-fa-upc,upc>>
|20140414.0


|hr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-hr-mte5.defnpout,mte5.defnpout>>
|20130509.2


|hu
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-hu-szeged_kr,szeged_kr>>
|20070724.2


|pt
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-pt-bosque,bosque>>
|20121123.2


|pt
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-pt-bosque,bosque>>
|20121123.2


|pt
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-pt-mm,mm>>
|20130119.2


|pt
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-pt-tbchp,tbchp>>
|20110419.2


|ru
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-ru-rdt,rdt>>
|20121123.2


|sl
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-sl-jos,jos>>
|20121123.2


|sv
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-sv-paroletags,paroletags>>
|20100215.2


|sv
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.hunpos-model-tagger-sv-suctags,suctags>>
|20100927.2


|====



[[engine-MateMorphTagger]]
==== MateMorphTagger

[small]#*_Role_:* __Part-of-speech tagger__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.matetools-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.matetools.MateMorphTagger__#

++++
<div class='paragraph'><p>DKPro Annotator for the MateToolsMorphTagger.</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.morph.Morpheme,Morpheme>>

|====





[[engine-MatePosTagger]]
==== MatePosTagger

[small]#*_Role_:* __Part-of-speech tagger__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.matetools-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.matetools.MatePosTagger__#

++++
<div class='paragraph'><p>DKPro Annotator for the MateToolsPosTagger</p></div>
++++


[discrete]
===== Parameters

`POSMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the part-of-speech tag to UIMA type mapping from this location instead of locating the
mapping automatically.</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.

Default: false</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-tagger-de-tiger,tiger>>
|20121024.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-tagger-en-conll2009,conll2009>>
|20130117.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-tagger-es-conll2009,conll2009>>
|20130117.1


|fr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-tagger-fr-ftb,ftb>>
|20130918.0


|zh
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-tagger-zh-conll2009,conll2009>>
|20130117.1


|====



[[engine-MeCabTagger]]
==== MeCabTagger

[small]#*_Role_:* __Part-of-speech tagger__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.mecab-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.mecab.MeCabTagger__#

++++
<div class='paragraph'><p>Annotator for the MeCab Japanese POS Tagger.</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>The language.</p></div>
++++

`strictZoning` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Strict zoning causes the segmentation to be applied only within the
boundaries of a zone annotation. This works only if a single zone type
is specified (the zone annotations should NOT overlap) or if no zone
type is specified - in which case the whole document is taken as a zone.
If strict zoning is turned off, multiple zone types can be specified.
A list of all zone boundaries (start and end) is created and segmentation
happens between them.</p></div>
++++

`writeSentence` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Sentence annotations.</p></div>
++++

`writeToken` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Token annotations.</p></div>
++++

`zoneTypes` (__String[]__) = `[de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Div]`  [optional]::
+
++++
<div class='paragraph'><p>A list of type names used for zoning.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| __none specified__


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.mecab.type.JapaneseToken,JapaneseToken>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|jp
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.mecab-model-tagger-jp-bin-linux-x86_32,bin-linux-x86_32>>
|.


|jp
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.mecab-model-tagger-jp-bin-linux-x86_64,bin-linux-x86_64>>
|.


|jp
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.mecab-model-tagger-jp-bin-osx-x86_64,bin-osx-x86_64>>
|.


|jp
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.mecab-model-tagger-jp-ipadic,ipadic>>
|.


|====



[[engine-OpenNlpPosTagger]]
==== OpenNlpPosTagger

[small]#*_Role_:* __Part-of-speech tagger__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.opennlp-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.opennlp.OpenNlpPosTagger__#

++++
<div class='paragraph'><p>Part-of-Speech annotator using OpenNLP. Requires Sentences to be annotated before.</p></div>
++++


[discrete]
===== Parameters

`POSMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the part-of-speech tag to UIMA type mapping from this location instead of locating
the mapping automatically.</p></div>
++++

`internTags` (__Boolean__) = `true`  [optional]::
+
++++
<div class='paragraph'><p>Use the String#intern() method on tags. This is usually a good idea to avoid
spaming the heap with thousands of strings representing only a few different tags.

Default: true</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.

Default: false</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|da
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-da-maxent,maxent>>
|20120616.1


|da
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-da-perceptron,perceptron>>
|20120616.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-de-maxent,maxent>>
|20120616.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-de-perceptron,perceptron>>
|20120616.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-en-maxent,maxent>>
|20120616.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-en-perceptron,perceptron>>
|20120616.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-en-perceptron-ixa,perceptron-ixa>>
|20131115.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-es-maxent,maxent>>
|20120410.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-es-maxent-ixa,maxent-ixa>>
|20140425.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-es-maxent-universal,maxent-universal>>
|20120410.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-es-perceptron,perceptron>>
|20120410.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-es-perceptron-ixa,perceptron-ixa>>
|20131115.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-es-perceptron-universal,perceptron-universal>>
|20120410.1


|it
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-it-perceptron,perceptron>>
|20130618.0


|nl
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-nl-maxent,maxent>>
|20120616.1


|nl
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-nl-perceptron,perceptron>>
|20120616.1


|pt
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-pt-maxent,maxent>>
|20120616.1


|pt
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-pt-mm-maxent,mm-maxent>>
|20130121.1


|pt
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-pt-mm-perceptron,mm-perceptron>>
|20130121.1


|pt
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-pt-perceptron,perceptron>>
|20120616.1


|sv
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-sv-maxent,maxent>>
|20120616.1


|sv
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-tagger-sv-perceptron,perceptron>>
|20120616.1


|====



[[engine-StanfordPosTagger]]
==== StanfordPosTagger

[small]#*_Role_:* __Part-of-speech tagger__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp.StanfordPosTagger__#

++++
<div class='paragraph'><p>Stanford Part-of-Speech tagger component.</p></div>
++++


[discrete]
===== Parameters

`POSMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location of the mapping file for part-of-speech tags to UIMA types.</p></div>
++++

`internTags` (__Boolean__) = `true`  [optional]::
+
++++
<div class='paragraph'><p>Use the String#intern() method on tags. This is usually a good idea to avoid
spaming the heap with thousands of strings representing only a few different tags.

Default: false</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model and tag set mapping.</p></div>
++++

`maxSentenceLength` (__Integer__) [optional]::
+
++++
<div class='paragraph'><p>Sentences with more tokens than the specified max amount will be ignored if this parameter
is set to a value larger than zero. The default value zero will allow all sentences to be
POS tagged.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location from which the model is read.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Variant of a model the model. Used to address a specific model if here are multiple models
for one language.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.

Default: false</p></div>
++++

`ptb3Escaping` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Enable all traditional PTB3 token transforms (like -LRB-, -RRB-).</p></div>
++++

`quoteBegin` (__String[]__) [optional]::
+
++++
<div class='paragraph'><p>List of extra token texts (usually single character strings) that should be treated like
opening quotes and escaped accordingly before being sent to the parser.</p></div>
++++

`quoteEnd` (__String[]__) [optional]::
+
++++
<div class='paragraph'><p>List of extra token texts (usually single character strings) that should be treated like
closing quotes and escaped accordingly before being sent to the parser.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|ar
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-ar-accurate,accurate>>
|20131112.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-de-dewac,dewac>>
|20140827.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-de-fast,fast>>
|20140827.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-de-fast-caseless,fast-caseless>>
|20140827.0


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-de-hgc,hgc>>
|20140827.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-en-bidirectional-distsim,bidirectional-distsim>>
|20140616.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-en-caseless-left3words-distsim,caseless-left3words-distsim>>
|20140827.0


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-en-fast.41,fast.41>>
|20130730.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-en-left3words-distsim,left3words-distsim>>
|20140616.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-en-twitter,twitter>>
|20130730.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-en-twitter-fast,twitter-fast>>
|20130914.0


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-en-wsj-0-18-bidirectional-distsim,wsj-0-18-bidirectional-distsim>>
|20160110.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-en-wsj-0-18-bidirectional-nodistsim,wsj-0-18-bidirectional-nodistsim>>
|20131112.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-en-wsj-0-18-caseless-left3words-distsim,wsj-0-18-caseless-left3words-distsim>>
|20140827.0


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-en-wsj-0-18-left3words-distsim,wsj-0-18-left3words-distsim>>
|20140616.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-en-wsj-0-18-left3words-nodistsim,wsj-0-18-left3words-nodistsim>>
|20131112.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-es-default,default>>
|20151014.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-es-distsim,distsim>>
|20150108.1


|fr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-fr-default,default>>
|20140616.1


|zh
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-zh-distsim,distsim>>
|20140616.1


|zh
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.stanfordnlp-model-tagger-zh-nodistsim,nodistsim>>
|20140616.1


|====



[[engine-TreeTaggerPosTagger]]
==== TreeTaggerPosTagger

[small]#*_Role_:* __Part-of-speech tagger__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.treetagger-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.treetagger.TreeTaggerPosTagger__#

++++
<div class='paragraph'><p>Part-of-Speech and lemmatizer annotator using TreeTagger.</p></div>
++++


[discrete]
===== Parameters

`POSMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the part-of-speech tag to UIMA type mapping from this location instead of locating
the mapping automatically.</p></div>
++++

`executablePath` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this TreeTagger executable instead of trying to locate the executable automatically.</p></div>
++++

`internTags` (__Boolean__) = `true`  [optional]::
+
++++
<div class='paragraph'><p>Use the String#intern() method on tags. This is usually a good idea to avoid
spaming the heap with thousands of strings representing only a few different tags.

Default: true</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelEncoding` (__String__) [optional]::
+
++++
<div class='paragraph'><p>The character encoding used by the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`performanceMode` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>TT4J setting: Disable some sanity checks, e.g. whether tokens contain line breaks (which is
not allowed). Turning this on will increase your performance, but the wrapper may throw
exceptions if illegal data is provided.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Log the tag set(s) when a model is loaded.

Default: false</p></div>
++++

`writeLemma` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Write lemma information.

Default: true</p></div>
++++

`writePOS` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Write part-of-speech information.

Default: true</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|bg
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-bg-le,le>>
|20160430.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-de-le,le>>
|20121207.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-en-le,le>>
|20151119.1


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-es-le,le>>
|20150724.1


|et
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-et-le,le>>
|20110124.1


|fi
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-fi-le,le>>
|20140704.1


|fr
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-fr-le,le>>
|20100111.1


|gl
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-gl-le,le>>
|20130516.1


|it
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-it-le,le>>
|20141020.1


|la
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-la-le,le>>
|20110819.1


|mn
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-mn-le,le>>
|20120925.1


|nl
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-nl-le,le>>
|20130107.1


|pl
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-pl-le,le>>
|20150506.1


|pt
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-pt-le,le>>
|20101115.2


|ru
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-ru-le,le>>
|20140505.1


|sk
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-sk-le,le>>
|20130725.1


|sw
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-sw-le,le>>
|20130729.1


|zh
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.treetagger-model-tagger-zh-le,le>>
|20101115.1


|====




=== Phonetic Transcriptor



.Analysis Components in group Phonetic Transcriptor (4)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-ColognePhoneticTranscriptor,ColognePhoneticTranscriptor>>
|pass:[Cologne phonetic (Kölner Phonetik) transcription based on Apache Commons Codec.]


|<<component-reference.adoc#engine-DoubleMetaphonePhoneticTranscriptor,DoubleMetaphonePhoneticTranscriptor>>
|pass:[Double-Metaphone phonetic transcription based on Apache Commons Codec.]


|<<component-reference.adoc#engine-MetaphonePhoneticTranscriptor,MetaphonePhoneticTranscriptor>>
|pass:[Metaphone phonetic transcription based on Apache Commons Codec.]


|<<component-reference.adoc#engine-SoundexPhoneticTranscriptor,SoundexPhoneticTranscriptor>>
|pass:[Soundex phonetic transcription based on Apache Commons Codec.]


|====



[[engine-ColognePhoneticTranscriptor]]
==== ColognePhoneticTranscriptor

[small]#*_Role_:* __Phonetic Transcriptor__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.commonscodec-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.commonscodec.ColognePhoneticTranscriptor__#

++++
<div class='paragraph'><p>Cologne phonetic (Kölner Phonetik) transcription based on Apache Commons Codec.
Works for German.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.phonetics.type.PhoneticTranscription,PhoneticTranscription>>

|====





[[engine-DoubleMetaphonePhoneticTranscriptor]]
==== DoubleMetaphonePhoneticTranscriptor

[small]#*_Role_:* __Phonetic Transcriptor__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.commonscodec-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.commonscodec.DoubleMetaphonePhoneticTranscriptor__#

++++
<div class='paragraph'><p>Double-Metaphone phonetic transcription based on Apache Commons Codec.
Works for English.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.phonetics.type.PhoneticTranscription,PhoneticTranscription>>

|====





[[engine-MetaphonePhoneticTranscriptor]]
==== MetaphonePhoneticTranscriptor

[small]#*_Role_:* __Phonetic Transcriptor__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.commonscodec-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.commonscodec.MetaphonePhoneticTranscriptor__#

++++
<div class='paragraph'><p>Metaphone phonetic transcription based on Apache Commons Codec.
Works for English.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.phonetics.type.PhoneticTranscription,PhoneticTranscription>>

|====





[[engine-SoundexPhoneticTranscriptor]]
==== SoundexPhoneticTranscriptor

[small]#*_Role_:* __Phonetic Transcriptor__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.commonscodec-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.commonscodec.SoundexPhoneticTranscriptor__#

++++
<div class='paragraph'><p>Soundex phonetic transcription based on Apache Commons Codec.
Works for English.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.phonetics.type.PhoneticTranscription,PhoneticTranscription>>

|====






=== Segmenter


include::{include-dir}sectionIntroSegmenter.adoc[]


.Analysis Components in group Segmenter (17)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-AnnotationByLengthFilter,AnnotationByLengthFilter>>
|pass:[Removes annotations that do not conform to minimum or maximum length constraints.]


|<<component-reference.adoc#engine-ArktweetTokenizer,ArktweetTokenizer>>
|pass:[ArkTweet tokenizer.]


|<<component-reference.adoc#engine-BreakIteratorSegmenter,BreakIteratorSegmenter>>
|pass:[BreakIterator segmenter.]


|<<component-reference.adoc#engine-CamelCaseTokenSegmenter,CamelCaseTokenSegmenter>>
|pass:[Split up existing tokens again if they are camel-case text.]


|<<component-reference.adoc#engine-ClearNlpSegmenter,ClearNlpSegmenter>>
|pass:[Tokenizer using Clear NLP.]


|<<component-reference.adoc#engine-GermanSeparatedParticleAnnotator,GermanSeparatedParticleAnnotator>>
|pass:[Annotator to be used for post-processing of German corpora that have been lemmatized and POS-tagged with the
TreeTagger, based on the STTS tagset.]


|<<component-reference.adoc#engine-JTokSegmenter,JTokSegmenter>>
|pass:[JTok segmenter.]


|<<component-reference.adoc#engine-LanguageToolSegmenter,LanguageToolSegmenter>>
|pass:[Segmenter using LanguageTool to do the heavy lifting.]


|<<component-reference.adoc#engine-LineBasedSentenceSegmenter,LineBasedSentenceSegmenter>>
|pass:[Annotates each line in the source text as a sentence.]


|<<component-reference.adoc#engine-OpenNlpSegmenter,OpenNlpSegmenter>>
|pass:[Tokenizer and sentence splitter using OpenNLP.]


|<<component-reference.adoc#engine-ParagraphSplitter,ParagraphSplitter>>
|pass:[This class creates paragraph annotations for the given input document.]


|<<component-reference.adoc#engine-PatternBasedTokenSegmenter,PatternBasedTokenSegmenter>>
|pass:[Split up existing tokens again at particular split-chars.]


|<<component-reference.adoc#engine-RegexTokenizer,RegexTokenizer>>
|pass:[This segmenter splits sentences and tokens based on regular expressions that define the sentence
and token boundaries.]


|<<component-reference.adoc#engine-StanfordSegmenter,StanfordSegmenter>>
|__No description__


|<<component-reference.adoc#engine-TokenMerger,TokenMerger>>
|pass:[Merges any Tokens that are covered by a given annotation type.]


|<<component-reference.adoc#engine-TokenTrimmer,TokenTrimmer>>
|pass:[Remove prefixes and suffixes from tokens.]


|<<component-reference.adoc#engine-WhitespaceTokenizer,WhitespaceTokenizer>>
|pass:[A strict whitespace tokenizer, i.e. tokenizes according to whitespaces and linebreaks only.]


|====



[[engine-AnnotationByLengthFilter]]
==== AnnotationByLengthFilter

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.tokit-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.tokit.AnnotationByLengthFilter__#

++++
<div class='paragraph'><p>Removes annotations that do not conform to minimum or maximum length constraints.

(This was previously called TokenFilter).</p></div>
++++


[discrete]
===== Parameters

`FilterTypes` (__String[]__) = `[]` ::
+
++++
<div class='paragraph'><p>A set of annotation types that should be filtered.</p></div>
++++

`MaxLengthFilter` (__Integer__) = `1000` ::
+
++++
<div class='paragraph'><p>Any annotation in filterAnnotations shorter than this value will be removed.</p></div>
++++

`MinLengthFilter` (__Integer__) = `0` ::
+
++++
<div class='paragraph'><p>Any annotation in filterTypes shorter than this value will be removed.</p></div>
++++








[[engine-ArktweetTokenizer]]
==== ArktweetTokenizer

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.arktools-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.arktools.ArktweetTokenizer__#

++++
<div class='paragraph'><p>ArkTweet tokenizer.</p></div>
++++








[[engine-BreakIteratorSegmenter]]
==== BreakIteratorSegmenter

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.tokit-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.tokit.BreakIteratorSegmenter__#

++++
<div class='paragraph'><p>BreakIterator segmenter.</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>The language.</p></div>
++++

`splitAtApostrophe` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Per default the Java BreakIterator does not split off contractions like
John's into two tokens. When this parameter is enabled, a non-default token split is
generated when an apostrophe (') is encountered.</p></div>
++++

`strictZoning` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Strict zoning causes the segmentation to be applied only within the
boundaries of a zone annotation. This works only if a single zone type
is specified (the zone annotations should NOT overlap) or if no zone
type is specified - in which case the whole document is taken as a zone.
If strict zoning is turned off, multiple zone types can be specified.
A list of all zone boundaries (start and end) is created and segmentation
happens between them.</p></div>
++++

`writeSentence` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Sentence annotations.</p></div>
++++

`writeToken` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Token annotations.</p></div>
++++

`zoneTypes` (__String[]__) = `[de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Div]`  [optional]::
+
++++
<div class='paragraph'><p>A list of type names used for zoning.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| __none specified__


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>

|====





[[engine-CamelCaseTokenSegmenter]]
==== CamelCaseTokenSegmenter

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.tokit-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.tokit.CamelCaseTokenSegmenter__#

++++
<div class='paragraph'><p>Split up existing tokens again if they are camel-case text.</p></div>
++++


[discrete]
===== Parameters

`deleteCover` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Wether to remove the original token.

Default: true</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>

|====





[[engine-ClearNlpSegmenter]]
==== ClearNlpSegmenter

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.clearnlp-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.clearnlp.ClearNlpSegmenter__#

++++
<div class='paragraph'><p>Tokenizer using Clear NLP.</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`strictZoning` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Strict zoning causes the segmentation to be applied only within the
boundaries of a zone annotation. This works only if a single zone type
is specified (the zone annotations should NOT overlap) or if no zone
type is specified - in which case the whole document is taken as a zone.
If strict zoning is turned off, multiple zone types can be specified.
A list of all zone boundaries (start and end) is created and segmentation
happens between them.</p></div>
++++

`writeSentence` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Sentence annotations.</p></div>
++++

`writeToken` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Token annotations.</p></div>
++++

`zoneTypes` (__String[]__) = `[de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Div]`  [optional]::
+
++++
<div class='paragraph'><p>A list of type names used for zoning.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| __none specified__


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>

|====





[[engine-GermanSeparatedParticleAnnotator]]
==== GermanSeparatedParticleAnnotator

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.tokit-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.tokit.GermanSeparatedParticleAnnotator__#

++++
<div class='paragraph'><p>Annotator to be used for post-processing of German corpora that have been lemmatized and POS-tagged with the
TreeTagger, based on the STTS tagset.

This Annotator deals with German particle verbs. Particle verbs consist of a particle and a stem, e.g. anfangen = an+fangen
There are many usages of German particle verbs where the stem and the particle are separated, e.g., Wir fangen gleich an.
The TreeTagger lemmatizes the verb stem as "fangen" and the separated particle as "an",
the proper verblemma "anfangen" is thus not available as an annotation.
The GermanSeparatedParticleAnnotator replaces the lemma of the stem of particle-verbs (e.g., fangen) by the proper verb lemma
(e.g. anfangen) and leaves the lemma of the separated particle unchanged.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>

|====





[[engine-JTokSegmenter]]
==== JTokSegmenter

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.jtok-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.jtok.JTokSegmenter__#

++++
<div class='paragraph'><p>JTok segmenter.</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>The language.</p></div>
++++

`strictZoning` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Strict zoning causes the segmentation to be applied only within the
boundaries of a zone annotation. This works only if a single zone type
is specified (the zone annotations should NOT overlap) or if no zone
type is specified - in which case the whole document is taken as a zone.
If strict zoning is turned off, multiple zone types can be specified.
A list of all zone boundaries (start and end) is created and segmentation
happens between them.</p></div>
++++

`writeParagraph` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Paragraph annotations.</p></div>
++++

`writeSentence` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Sentence annotations.</p></div>
++++

`writeToken` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Token annotations.</p></div>
++++

`zoneTypes` (__String[]__) = `[de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Div]`  [optional]::
+
++++
<div class='paragraph'><p>A list of type names used for zoning.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| __none specified__


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Paragraph,Paragraph>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>

|====





[[engine-LanguageToolSegmenter]]
==== LanguageToolSegmenter

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.languagetool-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.languagetool.LanguageToolSegmenter__#

++++
<div class='paragraph'><p>Segmenter using LanguageTool to do the heavy lifting. LanguageTool internally uses different
strategies for tokenization.</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>The language.</p></div>
++++

`strictZoning` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Strict zoning causes the segmentation to be applied only within the
boundaries of a zone annotation. This works only if a single zone type
is specified (the zone annotations should NOT overlap) or if no zone
type is specified - in which case the whole document is taken as a zone.
If strict zoning is turned off, multiple zone types can be specified.
A list of all zone boundaries (start and end) is created and segmentation
happens between them.</p></div>
++++

`writeSentence` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Sentence annotations.</p></div>
++++

`writeToken` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Token annotations.</p></div>
++++

`zoneTypes` (__String[]__) = `[de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Div]`  [optional]::
+
++++
<div class='paragraph'><p>A list of type names used for zoning.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| __none specified__


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>

|====





[[engine-LineBasedSentenceSegmenter]]
==== LineBasedSentenceSegmenter

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.tokit-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.tokit.LineBasedSentenceSegmenter__#

++++
<div class='paragraph'><p>Annotates each line in the source text as a sentence. This segmenter is not capable of creating
tokens! All respective parameters have no functionality.</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>The language.</p></div>
++++

`strictZoning` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Strict zoning causes the segmentation to be applied only within the
boundaries of a zone annotation. This works only if a single zone type
is specified (the zone annotations should NOT overlap) or if no zone
type is specified - in which case the whole document is taken as a zone.
If strict zoning is turned off, multiple zone types can be specified.
A list of all zone boundaries (start and end) is created and segmentation
happens between them.</p></div>
++++

`writeSentence` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Sentence annotations.</p></div>
++++

`writeToken` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Token annotations.</p></div>
++++

`zoneTypes` (__String[]__) = `[de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Div]`  [optional]::
+
++++
<div class='paragraph'><p>A list of type names used for zoning.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| __none specified__


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>

|====





[[engine-OpenNlpSegmenter]]
==== OpenNlpSegmenter

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.opennlp-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.opennlp.OpenNlpSegmenter__#

++++
<div class='paragraph'><p>Tokenizer and sentence splitter using OpenNLP.</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++

`segmentationModelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the segmentation model from this location instead of locating the model automatically.</p></div>
++++

`strictZoning` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Strict zoning causes the segmentation to be applied only within the
boundaries of a zone annotation. This works only if a single zone type
is specified (the zone annotations should NOT overlap) or if no zone
type is specified - in which case the whole document is taken as a zone.
If strict zoning is turned off, multiple zone types can be specified.
A list of all zone boundaries (start and end) is created and segmentation
happens between them.</p></div>
++++

`tokenizationModelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the tokenization model from this location instead of locating the model automatically.</p></div>
++++

`writeSentence` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Sentence annotations.</p></div>
++++

`writeToken` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Token annotations.</p></div>
++++

`zoneTypes` (__String[]__) = `[de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Div]`  [optional]::
+
++++
<div class='paragraph'><p>A list of type names used for zoning.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| __none specified__


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|da
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-sentence-da-maxent,maxent>>
|20120616.1


|da
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-token-da-maxent,maxent>>
|20120616.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-sentence-de-maxent,maxent>>
|20120616.1


|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-token-de-maxent,maxent>>
|20120616.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-sentence-en-maxent,maxent>>
|20120616.1


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-token-en-maxent,maxent>>
|20120616.1


|it
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-sentence-it-maxent,maxent>>
|20130618.0


|it
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-token-it-maxent,maxent>>
|20130618.0


|nb
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-sentence-nb-maxent,maxent>>
|20120131.1


|nb
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-token-nb-maxent,maxent>>
|20120131.1


|nl
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-sentence-nl-maxent,maxent>>
|20120616.1


|nl
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-token-nl-maxent,maxent>>
|20120616.1


|pt
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-sentence-pt-maxent,maxent>>
|20120616.1


|pt
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-token-pt-maxent,maxent>>
|20120616.1


|sv
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-sentence-sv-maxent,maxent>>
|20120616.1


|sv
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.opennlp-model-token-sv-maxent,maxent>>
|20120616.1


|====



[[engine-ParagraphSplitter]]
==== ParagraphSplitter

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.tokit-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.tokit.ParagraphSplitter__#

++++
<div class='paragraph'><p>This class creates paragraph annotations for the given input document. It searches for the
occurrence of two or more line-breaks (Unix and Windows) and regards this as the boundary between
paragraphs.</p></div>
++++


[discrete]
===== Parameters

`splitPattern` (__String__) = `((\r\n\r\n)+(\r\n)*)|((\n\n)+(\n)*)` ::
+
++++
<div class='paragraph'><p>A regular expression used to detect paragraph splits.

Default: #DOUBLE_LINE_BREAKS_PATTERN (split on two consecutive line breaks)</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| __none specified__


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Paragraph,Paragraph>>

|====





[[engine-PatternBasedTokenSegmenter]]
==== PatternBasedTokenSegmenter

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.tokit-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.tokit.PatternBasedTokenSegmenter__#

++++
<div class='paragraph'><p>Split up existing tokens again at particular split-chars.
The prefix states whether the split chars should be added as separate Token Tokens.
If the #INCLUDE_PREFIX precedes the split pattern, the pattern is included.
Consequently, patterns following the #EXCLUDE_PREFIX, will not be added as a Token.</p></div>
++++


[discrete]
===== Parameters

`deleteCover` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Wether to remove the original token.

Default: true</p></div>
++++

`patterns` (__String[]__)::
+
++++
<div class='paragraph'><p>A list of regular expressions, prefixed with #INCLUDE_PREFIX or
#EXCLUDE_PREFIX. If neither of the prefixes is used, #EXCLUDE_PREFIX is
assumed.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>

|====





[[engine-RegexTokenizer]]
==== RegexTokenizer

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.tokit-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.tokit.RegexTokenizer__#

++++
<div class='paragraph'><p>This segmenter splits sentences and tokens based on regular expressions that define the sentence
and token boundaries.
</p><p>
The default behaviour is to split sentences by a line break and tokens by whitespace.</div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>The language.</p></div>
++++

`sentenceBoundaryRegex` (__String__) = `` ::
+
++++
<div class='paragraph'><p>Define the sentence boundary. Default: \n (assume one sentence per line).</p></div>
++++

`strictZoning` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Strict zoning causes the segmentation to be applied only within the
boundaries of a zone annotation. This works only if a single zone type
is specified (the zone annotations should NOT overlap) or if no zone
type is specified - in which case the whole document is taken as a zone.
If strict zoning is turned off, multiple zone types can be specified.
A list of all zone boundaries (start and end) is created and segmentation
happens between them.</p></div>
++++

`tokenBoundaryRegex` (__String__) = `[\\s\n]+` ::
+
++++
<div class='paragraph'><p>Defines the pattern that is used as token end boundary. Default: [\s\n]+ (matching
whitespace and linebreaks.
</p><p>
When setting custom patterns, take into account that the final token is often terminated by a
linebreak rather than the boundary character. Therefore, the newline typically has to be
added to the group of matching characters, e.g. "tokenized-text" is correctly
tokenized with the pattern [-\n].</div>
++++

`writeSentence` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Sentence annotations.</p></div>
++++

`writeToken` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Token annotations.</p></div>
++++

`zoneTypes` (__String[]__) = `[de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Div]`  [optional]::
+
++++
<div class='paragraph'><p>A list of type names used for zoning.</p></div>
++++








[[engine-StanfordSegmenter]]
==== StanfordSegmenter

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp.StanfordSegmenter__#

++++
null
++++


[discrete]
===== Parameters

`allowEmptySentences` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Whether to generate empty sentences.</p></div>
++++

`boundaryFollowers` (__String[]__) = `[), ], }, \", ', '', \u2019, \u201D, -RRB-, -RSB-, -RCB-, ), ], }]`  [optional]::
+
++++
<div class='paragraph'><p>This is a Set of String that are matched with .equals() which are allowed to be tacked onto
the end of a sentence after a sentence boundary token, for example ")".</p></div>
++++

`boundaryToDiscard` (__String[]__) = `[, *NL*]`  [optional]::
+
++++
<div class='paragraph'><p>The set of regex for sentence boundary tokens that should be discarded.</p></div>
++++

`boundaryTokenRegex` (__String__) = `\\.|[!?]+`  [optional]::
+
++++
<div class='paragraph'><p>The set of boundary tokens. If null, use default.</p></div>
++++

`isOneSentence` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Whether to treat all input as one sentence.</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>The language.</p></div>
++++

`languageFallback` (__String__) [optional]::
+
++++

++++

`newlineIsSentenceBreak` (__String__) = `TWO_CONSECUTIVE`  [optional]::
+
++++
<div class='paragraph'><p>Strategy for treating newlines as paragraph breaks.</p></div>
++++

`regionElementRegex` (__String__) [optional]::
+
++++
<div class='paragraph'><p>A regular expression for element names containing a sentence region. Only tokens in such
elements will be included in sentences. The start and end tags themselves are not included in
the sentence.</p></div>
++++

`strictZoning` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Strict zoning causes the segmentation to be applied only within the
boundaries of a zone annotation. This works only if a single zone type
is specified (the zone annotations should NOT overlap) or if no zone
type is specified - in which case the whole document is taken as a zone.
If strict zoning is turned off, multiple zone types can be specified.
A list of all zone boundaries (start and end) is created and segmentation
happens between them.</p></div>
++++

`tokenRegexesToDiscard` (__String[]__) = `[]`  [optional]::
+
++++
<div class='paragraph'><p>The set of regex for sentence boundary tokens that should be discarded.</p></div>
++++

`writeSentence` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Sentence annotations.</p></div>
++++

`writeToken` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Token annotations.</p></div>
++++

`xmlBreakElementsToDiscard` (__String[]__) [optional]::
+
++++
<div class='paragraph'><p>These are elements like "p" or "sent", which will be wrapped into regex for approximate XML
matching. They will be deleted in the output, and will always trigger a sentence boundary.</p></div>
++++

`zoneTypes` (__String[]__) = `[de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Div]`  [optional]::
+
++++
<div class='paragraph'><p>A list of type names used for zoning.</p></div>
++++








[[engine-TokenMerger]]
==== TokenMerger

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.tokit-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.tokit.TokenMerger__#

++++
<div class='paragraph'><p>Merges any Tokens that are covered by a given annotation type. E.g. this component can be used
to create a single tokens from all tokens that constitute a multi-token named entity.</p></div>
++++


[discrete]
===== Parameters

`POSMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the tagset mapping.</p></div>
++++

`annotationType` (__String__)::
+
++++
<div class='paragraph'><p>Annotation type for which tokens should be merged.</p></div>
++++

`constraint` (__String__) [optional]::
+
++++
<div class='paragraph'><p>A constraint on the annotations that should be considered in form of a JXPath statement.
Example: set #PARAM_ANNOTATION_TYPE to a NamedEntity type and set the
#PARAM_CONSTRAINT to ".[value = 'LOCATION']" to merge only tokens that are
part of a location named entity.</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model and tag set mapping.</p></div>
++++

`lemmaMode` (__String__) = `JOIN` ::
+
++++
<div class='paragraph'><p>Configure what should happen to the lemma of the merged tokens. It is possible to JOIN
the lemmata to a single lemma (space separated), to REMOVE the lemma or LEAVE the lemma
of the first token as-is.</p></div>
++++

`posType` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Set a new POS tag for the new merged token. This is the mapped type. If this is specified,
tag set mapping will not be performed. This parameter has no effect unless PARAM_POS_VALUE
is also set.</p></div>
++++

`posValue` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Set a new POS value for the new merged token. This is the actual tag set value and is subject
to tagset mapping. For example when merging tokens for named entities, the new POS value
may be set to "NNP" (English/Penn Treebank Tagset).</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>

|====





[[engine-TokenTrimmer]]
==== TokenTrimmer

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.tokit-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.tokit.TokenTrimmer__#

++++
<div class='paragraph'><p>Remove prefixes and suffixes from tokens.</p></div>
++++


[discrete]
===== Parameters

`prefixes` (__String[]__)::
+
++++
<div class='paragraph'><p>List of prefixes to remove.</p></div>
++++

`suffixes` (__String[]__)::
+
++++
<div class='paragraph'><p>List of suffixes to remove.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>

|====





[[engine-WhitespaceTokenizer]]
==== WhitespaceTokenizer

[small]#*_Role_:* __Segmenter__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.tokit-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.tokit.WhitespaceTokenizer__#

++++
<div class='paragraph'><p>A strict whitespace tokenizer, i.e. tokenizes according to whitespaces and linebreaks only.
</p><p>
If PARAM_WRITE_SENTENCES is set to true, one sentence per line is assumed. Otherwise, no
sentences are created.</div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>The language.</p></div>
++++

`strictZoning` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Strict zoning causes the segmentation to be applied only within the
boundaries of a zone annotation. This works only if a single zone type
is specified (the zone annotations should NOT overlap) or if no zone
type is specified - in which case the whole document is taken as a zone.
If strict zoning is turned off, multiple zone types can be specified.
A list of all zone boundaries (start and end) is created and segmentation
happens between them.</p></div>
++++

`writeSentence` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Sentence annotations.</p></div>
++++

`writeToken` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create Token annotations.</p></div>
++++

`zoneTypes` (__String[]__) = `[de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Div]`  [optional]::
+
++++
<div class='paragraph'><p>A list of type names used for zoning.</p></div>
++++









=== Semantic role labeler



.Analysis Components in group Semantic role labeler (2)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-ClearNlpSemanticRoleLabeler,ClearNlpSemanticRoleLabeler>>
|pass:[ClearNLP semantic role labeller.]


|<<component-reference.adoc#engine-MateSemanticRoleLabeler,MateSemanticRoleLabeler>>
|pass:[DKPro Annotator for the MateTools Semantic Role Labeler.]


|====



[[engine-ClearNlpSemanticRoleLabeler]]
==== ClearNlpSemanticRoleLabeler

[small]#*_Role_:* __Semantic role labeler__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.clearnlp-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.clearnlp.ClearNlpSemanticRoleLabeler__#

++++
<div class='paragraph'><p>ClearNLP semantic role labeller.</p></div>
++++


[discrete]
===== Parameters

`expandArguments` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Normally the arguments point only to the head words of arguments in the dependency tree.
With this option enabled, they are expanded to the text covered by the minimal and maximal
token offsets of all descendants (or self) of the head word.</p>

<p>Warning: this parameter should be used with caution! For one, if the descentants of a
head word cover a non-continuous region of the text, this information is lost. The arguments
will appear to be spanning a continuous region. For another, the arguments may overlap with
each other. E.g. if a sentence contains a relative clause with a verb, the subject of the
main clause may be recognized as a dependent of the verb and may cause the whole main
clause to be recorded in the argument.</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Variant of a model the model. Used to address a specific model if here are multiple models
for one language.</p></div>
++++

`predModelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location from which the predicate identifier model is read.</p></div>
++++

`printTagSet` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Write the tag set(s) to the log when a model is loaded.</p></div>
++++

`roleModelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location from which the roleset classification model is read.</p></div>
++++

`srlModelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Location from which the semantic role labeling model is read.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency,Dependency>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.semantics.type.SemanticArgument,SemanticArgument>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.semantics.type.SemanticPredicate,SemanticPredicate>>

|====





[[engine-MateSemanticRoleLabeler]]
==== MateSemanticRoleLabeler

[small]#*_Role_:* __Semantic role labeler__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.matetools-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.matetools.MateSemanticRoleLabeler__#

++++
<div class='paragraph'><p>DKPro Annotator for the MateTools Semantic Role Labeler.
</p><p>
Please cite the following paper, if you use the semantic role labeler
Anders Björkelund, Love Hafdell, and Pierre Nugues.  Multilingual semantic role labeling. 
In Proceedings of The Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009),
pages 43--48, Boulder, June 4--5 2009. 
</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`modelLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Load the model from this location instead of locating the model automatically.</p></div>
++++

`modelVariant` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Override the default variant used to locate the model.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency,Dependency>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.semantics.type.SemanticArgument,SemanticArgument>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.semantics.type.SemanticPredicate,SemanticPredicate>>

|====



[discrete]
===== Models
[options="header"]
|====
|Language|Variant|Version

|de
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-srl-de-tiger,tiger>>
|20130105.0


|en
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-srl-en-conll2009,conll2009>>
|20130117.0


|es
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-srl-es-conll2009,conll2009>>
|20130320.0


|zh
|<<model-reference.adoc#model-de.tudarmstadt.ukp.dkpro.core.matetools-model-srl-zh-conll2009,conll2009>>
|20130117.0


|====




=== Stemmer



.Analysis Components in group Stemmer (1)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-SnowballStemmer,SnowballStemmer>>
|pass:[UIMA wrapper for the Snowball stemmer.]


|====



[[engine-SnowballStemmer]]
==== SnowballStemmer

[small]#*_Role_:* __Stemmer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.snowball-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.snowball.SnowballStemmer__#

++++
<div class='paragraph'><p>UIMA wrapper for the Snowball stemmer. Annotation types to be stemmed can beconfigured by a
FeaturePath.</p>
<p>If you use this component in a pipeline which uses stop word removal, make sure that it
runs after the stop word removal step, so only words that are no stop words are stemmed.</p></div>
++++


[discrete]
===== Parameters

`filterConditionOperator` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Specifies the operator for a filtering condition.
</p><p>
It is only used if <code>PARAM_FILTER_FEATUREPATH</code> is set.</div>
++++

`filterConditionValue` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Specifies the value for a filtering condition.
</p><p>
It is only used if <code>PARAM_FILTER_FEATUREPATH</code> is set.</div>
++++

`filterFeaturePath` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Specifies a feature path that is used in the filter. If this is set, you also have to specify
<code>PARAM_FILTER_CONDITION_OPERATOR</code> and <code>PARAM_FILTER_CONDITION_VALUE</code>.</p></div>
++++

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model.</p></div>
++++

`lowerCase` (__Boolean__) = `false`  [optional]::
+
++++
<div class='paragraph'><p>Per default the stemmer runs in case-sensitive mode. If this parameter is enabled, tokens
are lower-cased before being passed to the stemmer.

<table border="1" cellspacing="0">
<caption>Examples</caption>
<tr><th></th><th>false (default)</th><th>true</th></tr>
<tr><td>EDUCATIONAL</td><td>EDUCATIONAL</td><td>educ</td></tr>
<tr><td>Educational</td><td>Educat</td><td>educ</td></tr>
<tr><td>educational</td><td>educ</td><td>educ</td></tr>
</table></p></div>
++++

`paths` (__String[]__) [optional]::
+
++++
<div class='paragraph'><p>Specify a path that is used for annotation. Format is de.type.name/feature/path. All type
objects will be annotated with a IndexTermAnnotation. The value of the IndexTerm is specified
by the feature path.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| __none specified__


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Stem,Stem>>

|====






=== Topic Model


include::{include-dir}sectionIntroTopic_Model.adoc[]


.Analysis Components in group Topic Model (2)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-MalletTopicModelEstimator,MalletTopicModelEstimator>>
|pass:[Estimate an LDA topic model using Mallet and write it to a file.]


|<<component-reference.adoc#engine-MalletTopicModelInferencer,MalletTopicModelInferencer>>
|pass:[Infers the topic distribution over documents using a Mallet ParallelTopicModel.]


|====



[[engine-MalletTopicModelEstimator]]
==== MalletTopicModelEstimator

[small]#*_Role_:* __Topic Model__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.mallet-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.mallet.topicmodel.MalletTopicModelEstimator__#

++++
<div class='paragraph'><p>Estimate an LDA topic model using Mallet and write it to a file. It stores all incoming CAS' to
Mallet Instances before estimating the model, using a ParallelTopicModel.</p></div>
++++


[discrete]
===== Parameters

`alphaSum` (__Float__) = `1.0` ::
+
++++
<div class='paragraph'><p>The sum of alphas over all topics. Default: 1.0.
</p><p>
Another recommended value is 50 / T (number of topics).</div>
++++

`beta` (__Float__) = `0.01` ::
+
++++
<div class='paragraph'><p>Beta for a single dimension of the Dirichlet prior. Default: 0.01.</p></div>
++++

`burninPeriod` (__Integer__) = `100` ::
+
++++
<div class='paragraph'><p>The number of iterations before hyperparameter optimization begins. Default: 100</p></div>
++++

`displayInterval` (__Integer__) = `50` ::
+
++++
<div class='paragraph'><p>The interval in which to display the estimated topics. Default: 50.</p></div>
++++

`displayNTopicWords` (__Integer__) = `7` ::
+
++++
<div class='paragraph'><p>The number of top words to display during estimation. Default: 7.</p></div>
++++

`minTokenLength` (__Integer__) = `3` ::
+
++++
<div class='paragraph'><p>Ignore tokens (or lemmas, respectively) that are shorter than the given value. Default: 3.</p></div>
++++

`modelEntityType` (__String__) [optional]::
+
++++
<div class='paragraph'><p>If specific, the text contained in the given segmentation type annotations are fed as
separate units to the topic model estimator e.g.
de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.sentence. Text that is not within
such annotations is ignored.
</p><p>
By default, the full document text is used as a document.</div>
++++

`nIterations` (__Integer__) = `1000` ::
+
++++
<div class='paragraph'><p>The number of iterations during model estimation. Default: 1000.</p></div>
++++

`nThreads` (__Integer__) = `1` ::
+
++++
<div class='paragraph'><p>The number of threads to use during model estimation. Default: 1.</p></div>
++++

`nTopics` (__Integer__) = `10` ::
+
++++
<div class='paragraph'><p>The number of topics to estimate for the topic model.</p></div>
++++

`optimizeInterval` (__Integer__) = `50` ::
+
++++
<div class='paragraph'><p>Interval for optimizing Dirichlet hyperparameters. Default: 50</p></div>
++++

`randomSeed` (__Integer__) = `-1` ::
+
++++
<div class='paragraph'><p>Set random seed. If set to -1 (default), uses random generator.</p></div>
++++

`saveInterval` (__Integer__) = `0` ::
+
++++
<div class='paragraph'><p>Define how often to save a serialized model during estimation. Default: 0 (only save when
estimation is done).</p></div>
++++

`targetLocation` (__String__)::
+
++++
<div class='paragraph'><p>The target model file location.</p></div>
++++

`typeName` (__String__) = `de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token` ::
+
++++
<div class='paragraph'><p>The annotation type to use for the topic model. Default:
de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token.</p></div>
++++

`useLemma` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>If set, uses lemmas instead of original text as features.</p></div>
++++

`useSymmetricAlph` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Use a symmatric alpha value during model estimation? Default: false.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| __none specified__

|====





[[engine-MalletTopicModelInferencer]]
==== MalletTopicModelInferencer

[small]#*_Role_:* __Topic Model__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.mallet-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.mallet.topicmodel.MalletTopicModelInferencer__#

++++
<div class='paragraph'><p>Infers the topic distribution over documents using a Mallet ParallelTopicModel.</p></div>
++++


[discrete]
===== Parameters

`burnIn` (__Integer__) = `1` ::
+
++++
<div class='paragraph'><p>The number of iterations before hyperparameter optimization begins. Default: 1</p></div>
++++

`maxTopicAssignments` (__Integer__) = `0` ::
+
++++
<div class='paragraph'><p>Maximum number of topics to assign. If not set (or &lt;= 0), the number of topics in the
model divided by 10 is set.</p></div>
++++

`minTokenLength` (__Integer__) = `3` ::
+
++++
<div class='paragraph'><p>Ignore tokens (or lemmas, respectively) that are shorter than the given value. Default: 3.</p></div>
++++

`minTopicProb` (__Float__) = `0.2` ::
+
++++
<div class='paragraph'><p>Minimum topic proportion for the document-topic assignment.</p></div>
++++

`modelLocation` (__String__)::
+
++++

++++

`nIterations` (__Integer__) = `10` ::
+
++++
<div class='paragraph'><p>The number of iterations during inference. Default: 10.</p></div>
++++

`thinning` (__Integer__) = `5` ::
+
++++

++++

`typeName` (__String__) = `de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token` ::
+
++++
<div class='paragraph'><p>The annotation type to use as tokens. Default: Token</p></div>
++++

`useLemma` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>If set, uses lemmas instead of original text as features.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.mallet.type.TopicDistribution,TopicDistribution>>

|====






=== Transformer



.Analysis Components in group Transformer (13)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-CapitalizationNormalizer,CapitalizationNormalizer>>
|pass:[Takes a text and replaces wrong capitalization]


|<<component-reference.adoc#engine-CjfNormalizer,CjfNormalizer>>
|pass:[Converts traditional Chinese to simplified Chinese or vice-versa.]


|<<component-reference.adoc#engine-DictionaryBasedTokenTransformer,DictionaryBasedTokenTransformer>>
|pass:[Reads a tab-separated file containing mappings from one token to another.]


|<<component-reference.adoc#engine-ExpressiveLengtheningNormalizer,ExpressiveLengtheningNormalizer>>
|pass:[Takes a text and shortens extra long words]


|<<component-reference.adoc#engine-FileBasedTokenTransformer,FileBasedTokenTransformer>>
|pass:[Replaces all tokens that are listed in the file in #PARAM_MODEL_LOCATION by the string
specified in #PARAM_REPLACEMENT.]


|<<component-reference.adoc#engine-HyphenationRemover,HyphenationRemover>>
|pass:[Simple dictionary-based hyphenation remover.]


|<<component-reference.adoc#engine-RegexBasedTokenTransformer,RegexBasedTokenTransformer>>
|pass:[A JCasTransformerChangeBased_ImplBase implementation that replaces tokens based on a
regular expressions.]


|<<component-reference.adoc#engine-ReplacementFileNormalizer,ReplacementFileNormalizer>>
|pass:[Takes a text and replaces desired expressions This class should not work on tokens as some
expressions might span several tokens]


|<<component-reference.adoc#engine-SharpSNormalizer,SharpSNormalizer>>
|pass:[Takes a text and replaces sharp s]


|<<component-reference.adoc#engine-SpellingNormalizer,SpellingNormalizer>>
|pass:[Converts annotations of the type SpellingAnomaly into a SofaChangeAnnoatation.]


|<<component-reference.adoc#engine-StanfordPtbTransformer,StanfordPtbTransformer>>
|pass:[Uses the normalizing tokenizer of the Stanford CoreNLP tools to escape the text PTB-style.]


|<<component-reference.adoc#engine-TokenCaseTransformer,TokenCaseTransformer>>
|pass:[Change tokens to follow a specific casing: all upper case, all lower case, or 'normal case':
lowercase everything but the first character of a token and the characters immediately following
a hyphen.]


|<<component-reference.adoc#engine-UmlautNormalizer,UmlautNormalizer>>
|pass:[Takes a text and checks for umlauts written as "ae", "oe", or "ue" and normalizes them if they
really are umlauts depending on a frequency model.]


|====



[[engine-CapitalizationNormalizer]]
==== CapitalizationNormalizer

[small]#*_Role_:* __Transformer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.frequency.CapitalizationNormalizer__#

++++
<div class='paragraph'><p>Takes a text and replaces wrong capitalization</p></div>
++++


[discrete]
===== Parameters

`typesToCopy` (__String[]__) = `[]` ::
+
++++
<div class='paragraph'><p>A list of fully qualified type names that should be copied to the transformed CAS where
available. By default, no types are copied apart from DocumentMetaData, i.e. all
other annotations are omitted.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| __none specified__

|====





[[engine-CjfNormalizer]]
==== CjfNormalizer

[small]#*_Role_:* __Transformer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.languagetool-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.languagetool.CjfNormalizer__#

++++
<div class='paragraph'><p>Converts traditional Chinese to simplified Chinese or vice-versa.</p></div>
++++


[discrete]
===== Parameters

`direction` (__String__) = `TO_SIMPLIFIED` ::
+
++++

++++

`typesToCopy` (__String[]__) = `[]` ::
+
++++
<div class='paragraph'><p>A list of fully qualified type names that should be copied to the transformed CAS where
available. By default, no types are copied apart from DocumentMetaData, i.e. all
other annotations are omitted.</p></div>
++++








[[engine-DictionaryBasedTokenTransformer]]
==== DictionaryBasedTokenTransformer

[small]#*_Role_:* __Transformer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.transformation.DictionaryBasedTokenTransformer__#

++++
<div class='paragraph'><p>Reads a tab-separated file containing mappings from one token to another. All tokens that match
an entry in the first column are changed to the corresponding token in the second column.</p></div>
++++


[discrete]
===== Parameters

`commentMarker` (__String__) = `#` ::
+
++++
<div class='paragraph'><p>Lines starting with this character (or String) are ignored. Default: '#'</p></div>
++++

`modelEncoding` (__String__) = `UTF-8` ::
+
++++

++++

`modelLocation` (__String__)::
+
++++

++++

`separator` (__String__) = `` ::
+
++++
<div class='paragraph'><p>Separator for mappings file. Default: "\t" (TAB).</p></div>
++++

`typesToCopy` (__String[]__) = `[]` ::
+
++++
<div class='paragraph'><p>A list of fully qualified type names that should be copied to the transformed CAS where
available. By default, no types are copied apart from DocumentMetaData, i.e. all
other annotations are omitted.</p></div>
++++








[[engine-ExpressiveLengtheningNormalizer]]
==== ExpressiveLengtheningNormalizer

[small]#*_Role_:* __Transformer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.frequency.ExpressiveLengtheningNormalizer__#

++++
<div class='paragraph'><p>Takes a text and shortens extra long words</p></div>
++++


[discrete]
===== Parameters

`typesToCopy` (__String[]__) = `[]` ::
+
++++
<div class='paragraph'><p>A list of fully qualified type names that should be copied to the transformed CAS where
available. By default, no types are copied apart from DocumentMetaData, i.e. all
other annotations are omitted.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| __none specified__

|====





[[engine-FileBasedTokenTransformer]]
==== FileBasedTokenTransformer

[small]#*_Role_:* __Transformer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.transformation.FileBasedTokenTransformer__#

++++
<div class='paragraph'><p>Replaces all tokens that are listed in the file in #PARAM_MODEL_LOCATION by the string
specified in #PARAM_REPLACEMENT.</p></div>
++++


[discrete]
===== Parameters

`ignoreCase` (__Boolean__) = `false` ::
+
++++

++++

`modelLocation` (__String__)::
+
++++

++++

`replacement` (__String__)::
+
++++

++++

`typesToCopy` (__String[]__) = `[]` ::
+
++++
<div class='paragraph'><p>A list of fully qualified type names that should be copied to the transformed CAS where
available. By default, no types are copied apart from DocumentMetaData, i.e. all
other annotations are omitted.</p></div>
++++








[[engine-HyphenationRemover]]
==== HyphenationRemover

[small]#*_Role_:* __Transformer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.transformation.HyphenationRemover__#

++++
<div class='paragraph'><p>Simple dictionary-based hyphenation remover.</p></div>
++++


[discrete]
===== Parameters

`modelEncoding` (__String__) = `UTF-8` ::
+
++++

++++

`modelLocation` (__String__)::
+
++++

++++

`typesToCopy` (__String[]__) = `[]` ::
+
++++
<div class='paragraph'><p>A list of fully qualified type names that should be copied to the transformed CAS where
available. By default, no types are copied apart from DocumentMetaData, i.e. all
other annotations are omitted.</p></div>
++++








[[engine-RegexBasedTokenTransformer]]
==== RegexBasedTokenTransformer

[small]#*_Role_:* __Transformer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.transformation.RegexBasedTokenTransformer__#

++++
<div class='paragraph'><p>A JCasTransformerChangeBased_ImplBase implementation that replaces tokens based on a
regular expressions.
</p><p>
The parameters #PARAM_REGEX defines the regular expression to be searcher,
#PARAM_REPLACEMENT defines the string with which matching patterns are replaces.</div>
++++


[discrete]
===== Parameters

`regex` (__String__)::
+
++++
<div class='paragraph'><p>Define the regular expression to be replaced</p></div>
++++

`replacement` (__String__)::
+
++++
<div class='paragraph'><p>Define the string to replace matching tokens with</p></div>
++++

`typesToCopy` (__String[]__) = `[]` ::
+
++++
<div class='paragraph'><p>A list of fully qualified type names that should be copied to the transformed CAS where
available. By default, no types are copied apart from DocumentMetaData, i.e. all
other annotations are omitted.</p></div>
++++








[[engine-ReplacementFileNormalizer]]
==== ReplacementFileNormalizer

[small]#*_Role_:* __Transformer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.ReplacementFileNormalizer__#

++++
<div class='paragraph'><p>Takes a text and replaces desired expressions This class should not work on tokens as some
expressions might span several tokens</p></div>
++++


[discrete]
===== Parameters

`modelLocation` (__String__)::
+
++++
<div class='paragraph'><p>Location of a file which contains all replacing characters</p></div>
++++

`srcExpressionSurroundings` (__String__) = `IRRELEVANT` ::
+
++++

++++

`targetExpressionSurroundings` (__String__) = `NOTHING` ::
+
++++

++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.transform.type.SofaChangeAnnotation,SofaChangeAnnotation>>

|====





[[engine-SharpSNormalizer]]
==== SharpSNormalizer

[small]#*_Role_:* __Transformer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.frequency.SharpSNormalizer__#

++++
<div class='paragraph'><p>Takes a text and replaces sharp s</p></div>
++++


[discrete]
===== Parameters

`MinFrequencyThreshold` (__Integer__) = `100` ::
+
++++

++++

`typesToCopy` (__String[]__) = `[]` ::
+
++++
<div class='paragraph'><p>A list of fully qualified type names that should be copied to the transformed CAS where
available. By default, no types are copied apart from DocumentMetaData, i.e. all
other annotations are omitted.</p></div>
++++








[[engine-SpellingNormalizer]]
==== SpellingNormalizer

[small]#*_Role_:* __Transformer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.SpellingNormalizer__#

++++
<div class='paragraph'><p>Converts annotations of the type SpellingAnomaly into a SofaChangeAnnoatation.</p></div>
++++


[discrete]
===== Parameters

`typesToCopy` (__String[]__) = `[]` ::
+
++++
<div class='paragraph'><p>A list of fully qualified type names that should be copied to the transformed CAS where
available. By default, no types are copied apart from DocumentMetaData, i.e. all
other annotations are omitted.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.anomaly.type.SpellingAnomaly,SpellingAnomaly>>


| Outputs
| __none specified__

|====





[[engine-StanfordPtbTransformer]]
==== StanfordPtbTransformer

[small]#*_Role_:* __Transformer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp.StanfordPtbTransformer__#

++++
<div class='paragraph'><p>Uses the normalizing tokenizer of the Stanford CoreNLP tools to escape the text PTB-style. This
component operates directly on the text and does not require prior segmentation.</p></div>
++++


[discrete]
===== Parameters

`typesToCopy` (__String[]__) = `[]` ::
+
++++
<div class='paragraph'><p>A list of fully qualified type names that should be copied to the transformed CAS where
available. By default, no types are copied apart from DocumentMetaData, i.e. all
other annotations are omitted.</p></div>
++++








[[engine-TokenCaseTransformer]]
==== TokenCaseTransformer

[small]#*_Role_:* __Transformer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.transformation.TokenCaseTransformer__#

++++
<div class='paragraph'><p>Change tokens to follow a specific casing: all upper case, all lower case, or 'normal case':
lowercase everything but the first character of a token and the characters immediately following
a hyphen.</p></div>
++++


[discrete]
===== Parameters

`tokenCase` (__String__)::
+
++++
<div class='paragraph'>The case to convert tokens to:
<ul>
<li>UPPERCASE: uppercase everything.</li>
<li>LOWERCASE: lowercase everything.</li>
<li>NORMALCASE: retain first letter in word and after hyphens, lowercase everything else.</li>
</ul></div>
++++

`typesToCopy` (__String[]__) = `[]` ::
+
++++
<div class='paragraph'><p>A list of fully qualified type names that should be copied to the transformed CAS where
available. By default, no types are copied apart from DocumentMetaData, i.e. all
other annotations are omitted.</p></div>
++++








[[engine-UmlautNormalizer]]
==== UmlautNormalizer

[small]#*_Role_:* __Transformer__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.frequency.UmlautNormalizer__#

++++
<div class='paragraph'><p>Takes a text and checks for umlauts written as "ae", "oe", or "ue" and normalizes them if they
really are umlauts depending on a frequency model.</p></div>
++++


[discrete]
===== Parameters

`MinFrequencyThreshold` (__Integer__) = `100` ::
+
++++

++++

`typesToCopy` (__String[]__) = `[]` ::
+
++++
<div class='paragraph'><p>A list of fully qualified type names that should be copied to the transformed CAS where
available. By default, no types are copied apart from DocumentMetaData, i.e. all
other annotations are omitted.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| __none specified__

|====






=== Other



.Analysis Components in group Other (20)
[options="header"]
|====
|Component|Description


|<<component-reference.adoc#engine-AnnotationByTextFilter,AnnotationByTextFilter>>
|pass:[Reads a list of words from a text file (one token per line) and retains only tokens or other
annotations that match any of these words.]


|<<component-reference.adoc#engine-ApplyChangesAnnotator,ApplyChangesAnnotator>>
|pass:[Applies changes annotated using a SofaChangeAnnotation.]


|<<component-reference.adoc#engine-Backmapper,Backmapper>>
|pass:[After processing a file with the ApplyChangesAnnotator this annotator
can be used to map the annotations created in the cleaned view back to the
original view.]


|<<component-reference.adoc#engine-CompoundAnnotator,CompoundAnnotator>>
|pass:[Annotates compound parts and linking morphemes.]


|<<component-reference.adoc#engine-CorrectionsContextualizer,CorrectionsContextualizer>>
|pass:[This component assumes that some spell checker has already been applied upstream (e.g.]


|<<component-reference.adoc#engine-DictionaryAnnotator,DictionaryAnnotator>>
|pass:[Takes a plain text file with phrases as input and annotates the phrases in the CAS file.]


|<<component-reference.adoc#engine-JCasHolder,JCasHolder>>
|pass:[Utility analysis engine for use with CAS multipliers in uimaFIT pipelines.]


|<<component-reference.adoc#engine-NGramAnnotator,NGramAnnotator>>
|pass:[N-gram annotator.]


|<<component-reference.adoc#engine-NorvigSpellingCorrector,NorvigSpellingCorrector>>
|pass:[Creates SofaChangeAnnotations containing corrections for previously identified spelling
errors.]


|<<component-reference.adoc#engine-PosFilter,PosFilter>>
|pass:[Removes all tokens/lemmas/stems/POS tags (depending on the "Mode" setting) that do not match the
given parts of speech.]


|<<component-reference.adoc#engine-PosMapper,PosMapper>>
|pass:[Maps existing POS tags from one tagset to another using a user provided properties file.]


|<<component-reference.adoc#engine-ReadabilityAnnotator,ReadabilityAnnotator>>
|pass:[Assign a set of popular readability scores to the text.]


|<<component-reference.adoc#engine-RegexTokenFilter,RegexTokenFilter>>
|pass:[Remove every token that does or does not match a given regular expression.]


|<<component-reference.adoc#engine-SemanticFieldAnnotator,SemanticFieldAnnotator>>
|pass:[This Analysis Engine annotates
English single words with semantic field information retrieved from an ExternalResource.]


|<<component-reference.adoc#engine-StanfordDependencyConverter,StanfordDependencyConverter>>
|pass:[Converts a constituency structure into a dependency structure.]


|<<component-reference.adoc#engine-StopWordRemover,StopWordRemover>>
|pass:[Remove all of the specified types from the CAS if their covered text is in the stop word
dictionary.]


|<<component-reference.adoc#engine-Stopwatch,Stopwatch>>
|pass:[Can be used to measure how long the processing between two points in a pipeline takes.]


|<<component-reference.adoc#engine-TfidfAnnotator,TfidfAnnotator>>
|pass:[This component adds Tfidf annotations consisting of a term and a tfidf weight.]


|<<component-reference.adoc#engine-TfidfConsumer,TfidfConsumer>>
|pass:[This consumer builds a DfModel.]


|<<component-reference.adoc#engine-TrailingCharacterRemover,TrailingCharacterRemover>>
|pass:[Removing trailing character (sequences) from tokens, e.g. punctuation.]


|====



[[engine-AnnotationByTextFilter]]
==== AnnotationByTextFilter

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.annotations.AnnotationByTextFilter__#

++++
<div class='paragraph'><p>Reads a list of words from a text file (one token per line) and retains only tokens or other
annotations that match any of these words.</p></div>
++++


[discrete]
===== Parameters

`ignoreCase` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>If true, annotation texts are filtered case-independently. Default: true, i.e. words that
occur in the list with different casing are not filtered out.</p></div>
++++

`modelEncoding` (__String__) = `UTF-8` ::
+
++++

++++

`modelLocation` (__String__)::
+
++++

++++

`typeName` (__String__) = `de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token` ::
+
++++
<div class='paragraph'><p>Annotation type to filter. Default:
de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token.</p></div>
++++








[[engine-ApplyChangesAnnotator]]
==== ApplyChangesAnnotator

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.castransformation-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.castransformation.ApplyChangesAnnotator__#

++++
<div class='paragraph'><p>Applies changes annotated using a SofaChangeAnnotation.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.metadata.type.DocumentMetaData,DocumentMetaData>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.transform.type.SofaChangeAnnotation,SofaChangeAnnotation>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.metadata.type.DocumentMetaData,DocumentMetaData>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.transform.type.SofaChangeAnnotation,SofaChangeAnnotation>>

|====





[[engine-Backmapper]]
==== Backmapper

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.castransformation-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.castransformation.Backmapper__#

++++
<div class='paragraph'><p>After processing a file with the ApplyChangesAnnotator this annotator
can be used to map the annotations created in the cleaned view back to the
original view.</p></div>
++++


[discrete]
===== Parameters

`Chain` (__String[]__) = `[source, target]`  [optional]::
+
++++
<div class='paragraph'><p>Chain of views for backmapping. This should be the reverse of the chain of views that the
ApplyChangesAnnotator has used.

For example, if view A has been mapped to B using ApplyChangesAnnotator, then this
parameter should be set using an array containing [B, A].</p></div>
++++








[[engine-CompoundAnnotator]]
==== CompoundAnnotator

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.decompounding-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.decompounding.uima.annotator.CompoundAnnotator__#

++++
<div class='paragraph'><p>Annotates compound parts and linking morphemes.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Compound,Compound>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.CompoundPart,CompoundPart>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.LinkingMorpheme,LinkingMorpheme>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Split,Split>>

|====





[[engine-CorrectionsContextualizer]]
==== CorrectionsContextualizer

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.jazzy-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.jazzy.CorrectionsContextualizer__#

++++
<div class='paragraph'><p>This component assumes that some spell checker has already been applied upstream (e.g. Jazzy).
It then uses ngram frequencies from a frequency provider in order to rank the provided corrections.</p></div>
++++








[[engine-DictionaryAnnotator]]
==== DictionaryAnnotator

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.dictionaryannotator-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.dictionaryannotator.DictionaryAnnotator__#

++++
<div class='paragraph'><p>Takes a plain text file with phrases as input and annotates the phrases in the CAS file. The
annotation type defaults to NGram, but can be changed.

The component requires that Tokens and Sentencees are annotated in the CAS.

The format of the phrase file is one phrase per line, tokens are separated by space:

<pre>
this is a phrase
another phrase
</pre></p></div>
++++


[discrete]
===== Parameters

`annotationType` (__String__) [optional]::
+
++++
<div class='paragraph'><p>The annotation to create on matching phases. If nothing is specified, this defaults to
NGram.</p></div>
++++

`modelEncoding` (__String__) = `UTF-8` ::
+
++++
<div class='paragraph'><p>The character encoding used by the model.</p></div>
++++

`modelLocation` (__String__)::
+
++++
<div class='paragraph'><p>The file must contain one phrase per line - phrases will be split at " "</p></div>
++++

`value` (__String__) [optional]::
+
++++
<div class='paragraph'><p>The value to set the feature configured in #PARAM_VALUE_FEATURE to.</p></div>
++++

`valueFeature` (__String__) = `value`  [optional]::
+
++++
<div class='paragraph'><p>Set this feature on the created annotations.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| __none specified__

|====





[[engine-JCasHolder]]
==== JCasHolder

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.util.JCasHolder__#

++++
<div class='paragraph'><p>Utility analysis engine for use with CAS multipliers in uimaFIT pipelines.</p></div>
++++








[[engine-NGramAnnotator]]
==== NGramAnnotator

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.ngrams-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.ngrams.NGramAnnotator__#

++++
<div class='paragraph'><p>N-gram annotator.</p></div>
++++


[discrete]
===== Parameters

`N` (__Integer__) = `3` ::
+
++++
<div class='paragraph'><p>The length of the n-grams to generate (the "n" in n-gram).</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence,Sentence>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.NGram,NGram>>

|====





[[engine-NorvigSpellingCorrector]]
==== NorvigSpellingCorrector

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.norvig-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.norvig.NorvigSpellingCorrector__#

++++
<div class='paragraph'><p>Creates SofaChangeAnnotations containing corrections for previously identified spelling
errors.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.transform.type.SofaChangeAnnotation,SofaChangeAnnotation>>

|====





[[engine-PosFilter]]
==== PosFilter

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.posfilter-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.posfilter.PosFilter__#

++++
<div class='paragraph'><p>Removes all tokens/lemmas/stems/POS tags (depending on the "Mode" setting) that do not match the
given parts of speech.</p></div>
++++


[discrete]
===== Parameters

`Verbs` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Keep/remove verbs (true: keep, false: v)</p></div>
++++

`adj` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Keep/remove adjectives (true: keep, false: remove)</p></div>
++++

`adv` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Keep/remove adverbs (true: keep, false: remove)</p></div>
++++

`art` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Keep/remove articles (true: keep, false: remove)</p></div>
++++

`card` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Keep/remove cardinal numbers (true: keep, false: remove)</p></div>
++++

`conj` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Keep/remove conjunctions (true: keep, false: remove)</p></div>
++++

`n` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Keep/remove nouns (true: keep, false: remove)</p></div>
++++

`o` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Keep/remove "others" (true: keep, false: remove)</p></div>
++++

`pp` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Keep/remove prepositions (true: keep, false: remove)</p></div>
++++

`pr` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Keep/remove pronouns (true: keep, false: remove)</p></div>
++++

`punc` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>Keep/remove punctuation (true: keep, false: remove)</p></div>
++++

`typeToRemove` (__String__)::
+
++++
<div class='paragraph'><p>The fully qualified name of the type that should be filtered.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>


| Outputs
| __none specified__

|====





[[engine-PosMapper]]
==== PosMapper

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.posfilter-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.posfilter.PosMapper__#

++++
<div class='paragraph'><p>Maps existing POS tags from one tagset to another using a user provided properties file.</p></div>
++++


[discrete]
===== Parameters

`dkproMappingLocation` (__String__) [optional]::
+
++++
<div class='paragraph'><p>A properties file containing mappings from the new tagset to (fully qualified) DKPro POS
classes.<br>
If such a file is not supplied, the DKPro POS classes stay the same regardless of the new POS
tag value, and only the value is changed.</p></div>
++++

`mappingFile` (__String__)::
+
++++
<div class='paragraph'><p>A properties file containing POS tagset mappings.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>

|====





[[engine-ReadabilityAnnotator]]
==== ReadabilityAnnotator

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.readability-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.readability.ReadabilityAnnotator__#

++++
<div class='paragraph'><p>Assign a set of popular readability scores to the text.</p></div>
++++








[[engine-RegexTokenFilter]]
==== RegexTokenFilter

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.annotations.RegexTokenFilter__#

++++
<div class='paragraph'><p>Remove every token that does or does not match a given regular expression.</p></div>
++++


[discrete]
===== Parameters

`mustMatch` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>If this parameter is set to true (default), retain only tokens that match the regex given in
#PARAM_REGEX. If set to false, all tokens that match the given regex are removed.</p></div>
++++

`regex` (__String__)::
+
++++
<div class='paragraph'><p>Every token that does or does not match this regular expression will be removed.</p></div>
++++








[[engine-SemanticFieldAnnotator]]
==== SemanticFieldAnnotator

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.dictionaryannotator-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.dictionaryannotator.semantictagging.SemanticFieldAnnotator__#

++++
<div class='paragraph'><p>This Analysis Engine annotates
English single words with semantic field information retrieved from an ExternalResource.
This could be a lexical resource such as WordNet or a simple key-value map.
The annotation is stored in the SemanticField annotation type.</p></div>
++++


[discrete]
===== Parameters

`annotationType` (__String__)::
+
++++
<div class='paragraph'><p>Annotation types which should be annotated with semantic fields</p></div>
++++

`constraint` (__String__) [optional]::
+
++++
<div class='paragraph'><p>A constraint on the annotations that should be considered in form of a JXPath statement.
Example: set #PARAM_ANNOTATION_TYPE to a NamedEntity type and set the
#PARAM_CONSTRAINT to ".[value = 'LOCATION']" to annotate only tokens with semantic fields that are
part of a location named entity.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.lexmorph.type.pos.POS,POS>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma,Lemma>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.NamedEntity,NamedEntity>>

|====





[[engine-StanfordDependencyConverter]]
==== StanfordDependencyConverter

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp-gpl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.stanfordnlp.StanfordDependencyConverter__#

++++
<div class='paragraph'><p>Converts a constituency structure into a dependency structure.</p></div>
++++


[discrete]
===== Parameters

`language` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Use this language instead of the document language to resolve the model and tag set mapping.</p></div>
++++

`mode` (__String__) = `TREE`  [optional]::
+
++++
<div class='paragraph'><p>Sets the kind of dependencies being created.

</p><p>Default: DependenciesMode#COLLAPSED TREE</div>
++++

`originalDependencies` (__Boolean__) = `true` ::
+
++++
<div class='paragraph'><p>Create original dependencies. If this is disabled, universal dependencies are created. The
default is to create the original dependencies.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token,Token>>
<<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.constituent.Constituent,Constituent>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.syntax.type.dependency.Dependency,Dependency>>

|====





[[engine-StopWordRemover]]
==== StopWordRemover

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.stopwordremover-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.stopwordremover.StopWordRemover__#

++++
<div class='paragraph'><p>Remove all of the specified types from the CAS if their covered text is in the stop word
dictionary. Also remove any other of the specified types that is covered by a matching instance.</p></div>
++++


[discrete]
===== Parameters

`Paths` (__String[]__) [optional]::
+
++++
<div class='paragraph'><p>Feature paths for annotations that should be matched/removed. The default is

<pre>
StopWord.class.getName()
Token.class.getName()
Lemma.class.getName()+"/value"
</pre></p></div>
++++

`StopWordType` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Anything annotated with this type will be removed even if it does not match any word in the
lists.</p></div>
++++

`modelEncoding` (__String__) = `UTF-8` ::
+
++++
<div class='paragraph'><p>The character encoding used by the model.</p></div>
++++

`modelLocation` (__String[]__)::
+
++++
<div class='paragraph'><p>A list of URLs from which to load the stop word lists. If an URL is prefixed with a language
code in square brackets, the stop word list is only used for documents in that language.
Using no prefix or the prefix "[*]" causes the list to be used for every document.
Example: "[de]classpath:/stopwords/en_articles.txt"</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.StopWord,StopWord>>


| Outputs
| __none specified__

|====





[[engine-Stopwatch]]
==== Stopwatch

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.performance-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.performance.Stopwatch__#

++++
<div class='paragraph'><p>Can be used to measure how long the processing between two points in a pipeline takes.
For that purpose, the AE needs to be added two times, before and after the part of the pipeline that should be measured.</p></div>
++++


[discrete]
===== Parameters

`timerName` (__String__)::
+
++++
<div class='paragraph'><p>Name of the timer pair.
Upstream and downstream timer need to use the same name.</p></div>
++++

`timerOutputFile` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Name of the timer pair.
Upstream and downstream timer need to use the same name.</p></div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.type.TimerAnnotation,TimerAnnotation>>


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.type.TimerAnnotation,TimerAnnotation>>

|====





[[engine-TfidfAnnotator]]
==== TfidfAnnotator

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.frequency-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.frequency.tfidf.TfidfAnnotator__#

++++
<div class='paragraph'><p>This component adds Tfidf annotations consisting of a term and a tfidf weight. <br>
The annotator is type agnostic concerning the input annotation, so you have to specify the
annotation type and string representation. It uses a pre-serialized DfStore, which can be
created using the TfidfConsumer.</p></div>
++++


[discrete]
===== Parameters

`featurePath` (__String__)::
+
++++
<div class='paragraph'><p>This annotator is type agnostic, so it is mandatory to specify the type of the working
annotation and how to obtain the string representation with the feature path.</p></div>
++++

`lowercase` (__Boolean__) = `false`  [optional]::
+
++++
<div class='paragraph'><p>If set to true, the whole text is handled in lower case.</p></div>
++++

`tfdfPath` (__String__) [optional]::
+
++++
<div class='paragraph'><p>Provide the path to the Df-Model. When a shared SharedDfModel is bound to this
annotator, this is ignored.</p></div>
++++

`weightingModeIdf` (__String__) = `NORMAL`  [optional]::
+
++++
<div class='paragraph'><p>The model for inverse document frequency weighting.<br>
Invoke toString() on an enum of WeightingModeIdf for setup.
</p><p>
Default value is "NORMAL" yielding an unweighted idf.</div>
++++

`weightingModeTf` (__String__) = `NORMAL`  [optional]::
+
++++
<div class='paragraph'><p>The model for term frequency weighting.<br>
Invoke toString() on an enum of WeightingModeTf for setup.
</p><p>
Default value is "NORMAL" yielding an unweighted tf.</div>
++++




[discrete]
===== Inputs and outputs
[cols="h,v"]
|====
| Inputs 
| __none specified__


| Outputs
| <<typesystem-reference.adoc#type-de.tudarmstadt.ukp.dkpro.core.api.frequency.tfidf.type.Tfidf,Tfidf>>

|====





[[engine-TfidfConsumer]]
==== TfidfConsumer

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.frequency-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.frequency.tfidf.TfidfConsumer__#

++++
<div class='paragraph'><p>This consumer builds a DfModel. It collects the df (document frequency) counts for the
processed collection. The counts are serialized as a DfModel-object.</p></div>
++++


[discrete]
===== Parameters

`featurePath` (__String__)::
+
++++
<div class='paragraph'><p>This annotator is type agnostic, so it is mandatory to specify the type of the working
annotation and how to obtain the string representation with the feature path.</p></div>
++++

`lowercase` (__Boolean__) = `false` ::
+
++++
<div class='paragraph'><p>If set to true, the whole text is handled in lower case.</p></div>
++++

`targetLocation` (__String__)::
+
++++
<div class='paragraph'><p>Specifies the path and filename where the model file is written.</p></div>
++++








[[engine-TrailingCharacterRemover]]
==== TrailingCharacterRemover

[small]#*_Role_:* __Other__# +
[small]#*_Artifact ID:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer-asl__# +
[small]#*_Class:_* __de.tudarmstadt.ukp.dkpro.core.textnormalizer.annotations.TrailingCharacterRemover__#

++++
<div class='paragraph'><p>Removing trailing character (sequences) from tokens, e.g. punctuation.</p></div>
++++


[discrete]
===== Parameters

`minTokenLength` (__Integer__) = `1` ::
+
++++
<div class='paragraph'><p>All tokens that are shorter than the minimum token length after removing trailing chars are
completely removed. By default (1), empty tokens are removed. Set to 0 or a negative value if
no tokens should be removed.
</p><p>
Shorter tokens that do not have trailing chars removed are always retained, regardless of
their length.</div>
++++

`pattern` (__String__) = `[\\Q,-\u201C^\u00BB*\u2019()&/\"'\u00A9\u00A7'\u2014\u00AB\u00B7=\\E0-9A-Z]+` ::
+
++++
<div class='paragraph'><p>A regex to be trimmed from the end of tokens.
</p><p>
Default: "[\\Q,-“^»*’()&amp;/\"'©§'—«·=\\E0-9A-Z]+" (remove punctuations, special
characters and capital letters).</div>
++++









